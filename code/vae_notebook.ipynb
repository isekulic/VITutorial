{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# How to implement a Variational Autoencoder (VAE)\n",
    "\n",
    "A variational autoencoder observes data, infers a latent code for it and tries to reconstruct the data from that latent code. In contrast to regular autoencoders, the code of the VAE is **random**. That means that when presented with the same input, the VAE will produce a slightly different code each time. This makes its decoding process more robust, since it has to deal with noisy code.\n",
    "\n",
    "Another way of looking at a VAE is as a training procedure for a probablistic model. The model is \n",
    "$$p(x) = \\int p(z)p(x|z) dz$$\n",
    "where $z$ is the latent code and $x$ is the data. During training we need to infer a posterior over $z$. In the case of a VAE this is done by neural network.\n",
    "\n",
    "Assuming that the theory of VAEs has already been presented, we now dive straight into implementing them. If you need more background on VAEs, have a look at our [tutorial slides](https://github.com/philschulz/VITutorial/tree/master/modules) and the references therein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Framework\n",
    "\n",
    "For the purpose of this tutorial we are going to use [mxnet](https://mxnet.incubator.apache.org) which is a scalable deep learning library that has interfaces for several languages, including Python. We are going to import and abbreviate it as \"mx\". We will use mxnet to define a computation graph. This is done using the [symbol library](https://mxnet.incubator.apache.org/api/python/symbol.html). When building the VAE, all the methods that you use should be prefixed with `mx.sym`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os, logging, sys\n",
    "from os.path import join, exists\n",
    "from abc import ABC\n",
    "from typing import List, Tuple, Callable, Optional, Iterable\n",
    "from matplotlib import cm, pyplot as plt\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specify a couple of constants that will help us to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_LEARNING_RATE = 0.0003\n",
    "\n",
    "TRAIN_SET = 'train'\n",
    "VALID_SET = 'valid'\n",
    "TEST_SET = 'test'\n",
    "data_names = [TRAIN_SET, VALID_SET, TEST_SET]\n",
    "test_set = [TEST_SET]\n",
    "data_dir = join(os.curdir, \"binary_mnist\")\n",
    "\n",
    "# change this to mx.gpu(0) if you want to run your code on gpu\n",
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we set up basic logging facilities to print intermediate output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s [%(levelname)s]: %(message)s\", datefmt=\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "Throughout the tutorial we will use the binarised MNIST data set consisting of images of handwritten digits (0-9). \n",
    "The binarisation was done by sampling each pixel from a Bernoulli distribution with the pixel's original intensity being the Bernoulli parameter (see [this paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.141.1680&rep=rep1&type=pdf) for details).Each pixel has been mapped to either 0 or 1, meaning that pixels are either fully on or off. We use this data set because it allows us to use a rather simple product of Bernoullis as a likelihood. We download the data into a folder called \"binary_mnist\". This may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:08:56 [INFO]: Data file binary_mnist.train exists\n",
      "11:08:56 [INFO]: Data file binary_mnist.valid exists\n",
      "11:08:56 [INFO]: Data file binary_mnist.test exists\n"
     ]
    }
   ],
   "source": [
    "if not exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "for data_set in data_names:\n",
    "    file_name = \"binary_mnist.{}\".format(data_set)\n",
    "    goal = join(data_dir, file_name)\n",
    "    if exists(goal):\n",
    "        logging.info(\"Data file {} exists\".format(file_name))\n",
    "    else:\n",
    "        logging.info(\"Downloading {}\".format(file_name))\n",
    "        link = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_{}.amat\".format(\n",
    "            data_set)\n",
    "        urllib.request.urlretrieve(link, goal)\n",
    "        logging.info(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now we have the data on disk. We will load the training and test data later. Right now we just load the validation set to see what the data looks like. We'll grab 5 random numbers and visualise them (you can run this box several times to get 5 different digits each time). That the digits look a bit rough results from their pixels being binarised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:09:11 [INFO]: Reading ./binary_mnist/binary_mnist.valid into memory\n"
     ]
    }
   ],
   "source": [
    "file_name = join(data_dir, \"binary_mnist.{}\".format(VALID_SET))\n",
    "logging.info(\"Reading {} into memory\".format(file_name))\n",
    "valid_set = np.genfromtxt(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:09:32 [DEBUG]: update_title_pos\n",
      "11:09:32 [DEBUG]: findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/ivna/venv/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n",
      "11:09:32 [DEBUG]: update_title_pos\n",
      "11:09:32 [DEBUG]: update_title_pos\n",
      "11:09:32 [DEBUG]: update_title_pos\n",
      "11:09:32 [DEBUG]: update_title_pos\n",
      "11:09:32 [DEBUG]: update_title_pos\n",
      "11:09:32 [DEBUG]: update_title_pos\n",
      "11:09:32 [DEBUG]: update_title_pos\n",
      "11:09:32 [DEBUG]: update_title_pos\n",
      "11:09:32 [DEBUG]: update_title_pos\n",
      "11:09:32 [DEBUG]: update_title_pos\n",
      "11:09:32 [DEBUG]: update_title_pos\n",
      "11:09:32 [DEBUG]: update_title_pos\n",
      "11:09:32 [DEBUG]: update_title_pos\n",
      "11:09:33 [DEBUG]: update_title_pos\n",
      "11:09:33 [DEBUG]: update_title_pos\n",
      "11:09:33 [DEBUG]: update_title_pos\n",
      "11:09:33 [DEBUG]: update_title_pos\n",
      "11:09:33 [DEBUG]: update_title_pos\n",
      "11:09:33 [DEBUG]: update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_indeces = np.random.randint(valid_set.shape[0], size=5)\n",
    "random_pictures = valid_set[random_indeces, :]\n",
    "width = height = int(sqrt(random_pictures.shape[1]))\n",
    "plot, axes = plt.subplots(1,5,  sharex='col', sharey='row', figsize=(15,3))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(np.reshape(random_pictures[i,:],(width,height)), cmap=cm.Greys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having acquainted ourselves with the data we can now proceed to build our VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagonal Gaussian VAE\n",
    "\n",
    "The most basic VAE model is one where we assume that the latent variable is multiviariate Gaussian. We fix the prior to be standard normal. During inference, we use a multivariate Gaussian variational distribution with diagonal covariance matrix. This means that we are only modelling variance but not covariance (in fact, a k-dimensional Guassian with diagonal covariance has the same density as a product of k independent univariate Gaussians). Geometrically, this variational distribution can only account for axis-aligned elliptical densities. It is thus rather limited in its modelling capabilities. Still, because it uses a neural network under the hood, it is very expressive. \n",
    "\n",
    "In this tutorial, we will model the mist binarised digit data set. Each image is encoded as a 784-dimensional vector. We will model each of these vectors as a product of 784 Bernoullis (of course, there are better models but we want to keep it simple). Our likelihood is thus a product of independent Bernoullis. The resulting model is formally specified as \n",
    "\n",
    "\\begin{align}z \\sim \\mathcal{N}(0,I) && x_i|z \\sim Bernoulli(NN_{\\theta}(z))~~~ i \\in \\{1,2,\\ldots, 784\\} \\ .\\end{align}\n",
    "\n",
    "The variational approximation is given by $$q(z|x) = \\mathcal{N}(NN_{\\lambda}(x), NN_{\\lambda}(x)).$$\n",
    "\n",
    "Notice that both the Bernoulli likelihood and the Gaussian variational distribution use NNs to compute their parameters. The parameters of the NNs, however, are different ($\\theta$ and $\\lambda$, respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "We will spread our implementation across 3 classes. This design choice is motivated by the desire to make our models as modular as possible. This will later allow us to mix and match different likelihoods and variational distributions.\n",
    "\n",
    "* **Generator**: This class defines our likelihood. Given a latent value, it produces a data sample or assigns a density to an existing data point.\n",
    "* **InferenceNetwork**: This neural network computes the parameters of the variational approximation from a data point.\n",
    "* **VAE**: This is the variational autoencoder. It combines a Generator and an InferenceNetwork and trains them jointly. Once trained, it can generate random data points or try to reproduce data presented to it.\n",
    "\n",
    "Below we have specified these classes abstractly. Make sure you understand what each method is supposed to be doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(ABC):\n",
    "    \"\"\"\n",
    "    Generator network.\n",
    "\n",
    "    :param data_dims: Dimensionality of the generated data.\n",
    "    :param layer_sizes: Size of each hidden layer in the network.\n",
    "    :param act_type: The activation after each hidden layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dims: int, layer_sizes: List[int], act_type: str) -> None:\n",
    "        self.data_dims = data_dims\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.act_type = act_type\n",
    "\n",
    "    def generate_sample(self, latent_state: mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Generate a data sample from a latent state.\n",
    "\n",
    "        :param latent_state: The latent input state.\n",
    "        :return: A data sample.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def train(self, latent_state: mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Train the generator from a given latent state.\n",
    "        \n",
    "        :param latent_state: The latent input state.\n",
    "        :return: The loss symbol used for training.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        \n",
    "class InferenceNetwork(ABC):\n",
    "    \"\"\"\n",
    "    A network to infer distributions over latent states.\n",
    "\n",
    "    :param latent_variable_size: The dimensionality of the latent variable.\n",
    "    :param layer_sizes: Size of each hidden layer in the network.\n",
    "    :param act_type: The activation after each hidden layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, latent_variable_size: int, layer_sizes: List[int], act_type: str) -> None:\n",
    "        self.latent_var_size = latent_variable_size\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.act_type = act_type\n",
    "\n",
    "    def inference(self, data: mx.sym.Symbol) -> Tuple[mx.sym.Symbol, ...]:\n",
    "        \"\"\"\n",
    "        Infer the parameters of the distribution over latent values.\n",
    "\n",
    "        :param data: A data sample.\n",
    "        :return: The parameters of the distribution.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def get_kl_loss(params_q: Iterable[mx.sym.Symbol], params_p: Iterable[mx.sym.Symbol]) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Create a loss symbol for the kl term associated with the inference net.\n",
    "        \n",
    "        :param params_q: The parameters of the variational distribution.\n",
    "        :param params_p: The parameters of the model prior.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "class VAE(ABC):\n",
    "    \"\"\"\n",
    "    A variational autoencoding model (Kingma and Welling, 2014).\n",
    "\n",
    "    :param generator: A generator network that specifies the likelihood of the model.\n",
    "    :param inference_net: An inference network that specifies the distribution over latent values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, generator: Generator, inference_net: InferenceNetwork) -> None:\n",
    "        self.generator = generator\n",
    "        self.inference_net = inference_net\n",
    "\n",
    "    def train(self, data: mx.sym.Symbol, label: mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Train the generator and inference network jointly by optimising the ELBO.\n",
    "\n",
    "        :param data: The training data.\n",
    "        :param label: Copy of the training data.\n",
    "        :return: A grouped list of loss symbols.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def generate_reconstructions(self, data: mx.sym.Symbol, n: int) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Generate a number of reconstructions of input data points.\n",
    "\n",
    "        :param data: The input data.\n",
    "        :param n: Number of reconstructions per data point.\n",
    "        :return: The reconstructed data.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def phantasize(self, n: int) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Generate data by randomly sampling from the prior.\n",
    "\n",
    "        :param n: Number of sampled data points.\n",
    "        :return: Randomly generated data points.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Let us start by implementing the generator. This is pretty much a standard neural network. The main point of this exercise is to get you comfortable with mxnet. Complete all the TODOs below. Before starting, check mxnet's [fully connected layer](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.FullyConnected) and [activation functions](https://mxnet.incubator.apache.org/api/python/symbol.html#mxnet.symbol.Activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductOfBernoullisGenerator(Generator):\n",
    "    \"\"\"\n",
    "    A generator that produces binary vectors whose entries are independent Bernoulli draws.\n",
    "\n",
    "    :param data_dims: Dimensionality of the generated data.\n",
    "    :param layer_sizes: Size of each hidden layer in the network.\n",
    "    :param act_type: The activation after each hidden layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dims: int, layer_sizes=List[int], act_type=str) -> None:\n",
    "        super().__init__(data_dims, layer_sizes, act_type)\n",
    "        # TODO choose the correct output activation for a Bernoulli variable. This should just be a string.\n",
    "        self.output_act = 'sigmoid' # or softmax?\n",
    "\n",
    "    def _preactivation(self, latent_state: mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Computes the pre-activation of the generator, i.e. the hidden state before the final output activation.\n",
    "\n",
    "        :param latent_state: The input latent state.\n",
    "        :return: The pre-activation before output activation.\n",
    "        \"\"\"\n",
    "        prev_out = latent_state\n",
    "        for i, size in enumerate(self.layer_sizes):\n",
    "            # TODO for each layer size in layer_sizes, introduce a layer that performs an affine transformation \n",
    "            # (implemented by mx.sym.FullyConnected) followed by a non-linearity that is specified by self.act_type.\n",
    "            # Call the resulting symbol act_i and uncomment the line below\n",
    "            \n",
    "            fc_i  = mx.sym.FullyConnected(prev_out, num_hidden=size, name='gen_FC%d' % i)\n",
    "            act_i = mx.sym.Activation(data=fc_i, act_type=self.act_type, name='gen_Act%d' % i)\n",
    "            prev_out = act_i\n",
    " \n",
    "\n",
    "        # The output layer that gives pre_activations for multiple Bernoulli softmax between 0 and 1\n",
    "        fc_out = mx.sym.FullyConnected(data=prev_out, num_hidden=self.data_dims, name=\"gen_fc_out\")\n",
    "\n",
    "        return fc_out\n",
    "    \n",
    "    def generate_sample(self, latent_state: mx.sym.Symbol, binarise: bool = False) -> Tuple[mx.sym.Symbol, mx.sym.Symbol]:\n",
    "        \"\"\"\n",
    "        Generates a data sample. The stochasticity in the sampling\n",
    "        process comes from the latent_state. Either returns the Bernoulli parameters or the maximally likely\n",
    "        outcome.\n",
    "\n",
    "        :param latent_state: The input latent state.\n",
    "        :param binarise: Return discrete values instead of Bernoulli parameters.\n",
    "        :return: A vector of Bernoulli draws and the latent state from which they were generated.\n",
    "        \"\"\"\n",
    "        act = mx.sym.Activation(data=self._preactivation(latent_state=latent_state), act_type=self.output_act,\n",
    "                                name=\"gen_act_out\")\n",
    "        out = act > 0.5 if binarise else act\n",
    "        return out, latent_state\n",
    "    \n",
    "    def train(self, latent_state=mx.sym.Symbol, label=mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Train the generator from a given latent state.\n",
    "\n",
    "        :param latent_state: The input latent state.\n",
    "        :param label: A binary vector (same as input for inference module).\n",
    "        :return: The loss symbol used for training.\n",
    "        \"\"\"\n",
    "        output = mx.sym.Activation(data=self._preactivation(latent_state=latent_state), act_type=self.output_act,\n",
    "                                   name=\"output_act\")\n",
    "        return mx.sym.MakeLoss(-mx.sym.sum(label * mx.sym.log(output) + (1-label) * mx.sym.log(1-output), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now move on to the inference network. Recall that this network will return the parameters of a diagonal Gaussian. Thus, we need to return two vectors of the same size: a mean and a standard deviation vector. (Formally, the parameters of the Gaussian are the variances. However, from the derivation of the Gaussian reparametrisation we know that we\n",
    "need the standard deviations to generate a Gaussian random variable $z$ as transformation of a standard Gaussian variable $\\epsilon$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Exercise 2.a\n",
    "To train our VAE we need to compute the KL of the prior distribution from the variational approximation. Assuming that\n",
    "the prior is standard normal the KL for the a diagonal Gaussian variational approximation is\n",
    "$$ 0.5 * \\left(\\sum_i - \\log(\\sigma_i^2) - 1 + \\sigma_i^2 + \\mu_i^2 \\right) \\ . $$\n",
    "We use this KL divergence in the get_kl_loss method below of the GaussianInferenceNetwork. (Losses in mxnet are defined using the [MakeLoss](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.MakeLoss) symbol.) Please implement the function diagonal_gaussian_kl. Use the [sum](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.sum) and [log](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.log) symbols in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagonal_gaussian_kl(mean: mx.sym.Symbol, std: mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "    \"\"\"\n",
    "    Computes the KL divergence of a standard normal distribution from a diagonal Gaussian.\n",
    "    \n",
    "    :param mean: The mean of the diagonal Gaussian.\n",
    "    :param std: The standard deviations of the diagonal Gaussian.\n",
    "    :return: The value of the Kl divergence.\n",
    "    \"\"\"\n",
    "    # TODO: implement the diagonal gaussian Kl divergence\n",
    "    \n",
    "    kl_divergence = 0.5 * mx.sym.sum(-mx.sym.log(std**2)-1 + std**2 + mean**2, axis=1)\n",
    "    return kl_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.b\n",
    "We can finally implement the Gaussian reparametrisation. Fill in the correct code to perform the sampling in the sample_latent_state method.\n",
    "\n",
    "**Hint:** In this exercise you will need to draw a random Gaussian sample (see [here](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.random_normal)). The operator requires a\n",
    "shape whose first entry is the batch size. The batch size is not known to you during implementation, however.\n",
    "You can leave it underspecified by choosing $0$ as a value. When you combine the sampling operator with another\n",
    "operator mxnet will infer the correct the batch size for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianInferenceNetwork(InferenceNetwork):\n",
    "    \"\"\"\n",
    "    An inference network that predicts the parameters of a diagonal Gaussian and samples from that distribution.\n",
    "\n",
    "    :param latent_variable_size: The dimensionality of the latent variable.\n",
    "    :param layer_sizes: Size of each hidden layer in the network.\n",
    "    :param act_type: The activation after each hidden layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, latent_variable_size: int, layer_sizes: List[int], act_type: str):\n",
    "        super().__init__(latent_variable_size, layer_sizes, act_type)\n",
    "\n",
    "    def inference(self, data: mx.sym.Symbol) -> Tuple[mx.sym.Symbol, mx.sym.Symbol]:\n",
    "        \"\"\"\n",
    "        Infer the mean and standard deviation.\n",
    "\n",
    "        :param data: A data sample.\n",
    "        :return: The mean and standard deviation.\n",
    "        \"\"\"\n",
    "        # We choose to share the first layer between the networks that compute the standard deviations\n",
    "        # and means. This is a fairly standard design choice.\n",
    "        shared_layer = mx.sym.FullyConnected(data=data, num_hidden=self.layer_sizes[0], name=\"inf_joint_fc\")\n",
    "        shared_layer = mx.sym.Activation(data=shared_layer, act_type=self.act_type, name=\"inf_joint_act\")\n",
    "\n",
    "        prev_out = shared_layer\n",
    "        for i, size in enumerate(self.layer_sizes[1:]):\n",
    "            # TODO: do what you did for the generator in exercise 1.\n",
    "            mean_fc_i = mx.sym.FullyConnected(data=prev_out, num_hidden=size, name=\"FC_m_%d\" % i)\n",
    "            mean_act_i = mx.sym.Activation(data=mean_fc_i, act_type=self.act_type, name=\"Act_m_%d\" %i)\n",
    "            prev_out = mean_act_i\n",
    "        mean = mx.sym.FullyConnected(data=prev_out, num_hidden=self.latent_var_size, name=\"inf_mean_compute\")\n",
    "\n",
    "        prev_out = shared_layer\n",
    "        for i, size in enumerate(self.layer_sizes[1:]):\n",
    "            # TODO: again, same exercise.\n",
    "            var_fc_i = mx.sym.FullyConnected(data=prev_out, num_hidden=size, name=\"FC_v_%d\" % i)\n",
    "            var_act_i = mx.sym.Activation(data=var_fc_i, act_type=self.act_type, name=\"Act_v_%d\" %i)\n",
    "            prev_out = var_act_i\n",
    "        # TODO: The standard deviation is constrained to be positive for non-degenerate Gaussians. Take the\n",
    "        # prev_out symbol and transform it into a vector of positive reals.\n",
    "        std = mx.sym.Activation(mx.sym.FullyConnected(data=prev_out, num_hidden=self.latent_var_size, name=\"var_compute\"),\n",
    "                                act_type='softrelu', name='softrelu_')\n",
    "\n",
    "        return mean, std\n",
    "    \n",
    "    def get_kl_loss(self, mean: mx.sym.Symbol, std: mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "        return mx.sym.MakeLoss(diagonal_gaussian_kl(mean, std), name=\"gaussian_kl_loss\")\n",
    "\n",
    "    def sample_latent_state(self, mean: mx.sym.Symbol, std: mx.sym.Symbol, n: Optional[int] = 1) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Sample a value for the latent Gaussian variable.\n",
    "\n",
    "        :param mean: The mean of the Gaussian.\n",
    "        :param std: The standard deviation of the Gaussian.\n",
    "        :param n: Number of samples to be produced.\n",
    "        :return: A Gaussian sample.\n",
    "        \"\"\"\n",
    "        if n > 1:\n",
    "            # TODO: make sure this can be used during training\n",
    "            mean = mx.sym.tile(data=mean, reps=(n,1), name=\"inf_net_replicate_mean\")\n",
    "            std = mx.sym.tile(data=std, reps=(n,1), name=\"inf_net_replicate_std\")\n",
    "        # TODO: This is where the magic happens! Draw a sample from the Gaussian using the Gaussian reparametrisation\n",
    "        # trick and return it.\n",
    "        return mean + std * mx.sym.random_normal(loc=0, scale=1, shape=(0, self.latent_var_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "The only thing that is left to do is to implement VAE training. To train our VAE we will maximise the ELBO:\n",
    "$$ \\mathbb{E}\\left[ \\log p(x|z) \\right] - \\text{KL}(q(z|x)||p(z)) \\ . $$\n",
    "By default, MXNet's optimisers minimise losses instead of maximising objectives. We thus turn the ELBO into a loss by taking its negative. We already get the (sampled) cross entropy loss and (analytically computed) KL divergence as return values form calls to the Generator and inference network respectively. Your job is to combine them into one loss. In mxnet this can be done using the [Group symbol](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.Group). If a list of losses is provided as an argument to this symbol, the optimiser will add up these losses.\n",
    "\n",
    "**Note**: We could just as well have added up the values of the cross-entropy and the KL divergence and put the resulting loss into a MakeLoss symbol. The reason why we want to separate these two terms of the loss is that it allows us to output KL divergence. We will use this below when defining the KLMetric. Besides tracking the ELBO, which is our optimisation objective, we can also track to KL divergence to see how far the variational approximation moves away from the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianVAE(VAE):\n",
    "    \"\"\"\n",
    "    A VAE with Gaussian latent variables. It assumes a standard normal prior on the latent values.\n",
    "\n",
    "    :param generator: A generator network that specifies the likelihood of the model.\n",
    "    :param inference_net: An inference network that specifies the Gaussian over latent values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 generator: Generator,\n",
    "                 inference_net: GaussianInferenceNetwork,\n",
    "                 kl_divergence: Callable) -> None:\n",
    "        self.generator = generator\n",
    "        self.inference_net = inference_net\n",
    "        self.kl_divergence = kl_divergence\n",
    "\n",
    "    def train(self, data: mx.sym.Symbol, label: mx.sym.Symbol) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Train the generator and inference network jointly by optimising the ELBO.\n",
    "\n",
    "        :param data: The training data.\n",
    "        :param label: Copy of the training data.\n",
    "        :return: A list of loss symbols.\n",
    "        \"\"\"\n",
    "        # TODO implement the train method. Make sure to include all relevant loss terms.\n",
    "        mean, std = self.inference_net.inference(data)\n",
    "        latent_state = self.inference_net.sample_latent_state(mean, std)\n",
    "        kl_loss = self.inference_net.get_kl_loss(mean, std)\n",
    "        \n",
    "        cross_entropy = self.generator.train(latent_state, label)\n",
    "        \n",
    "        loss = mx.sym.Group([-cross_entropy, kl_loss])\n",
    "        return loss\n",
    "        #return mx.sym.MakeLoss(kl_loss - cross_entropy, name=\"negative_ELBO\")\n",
    "\n",
    "    def generate_reconstructions(self, data: mx.sym.Symbol, n: int) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Generate a number of reconstructions of input data points.\n",
    "\n",
    "        :param data: The input data.\n",
    "        :param n: Number of reconstructions per data point.\n",
    "        :return: The reconstructed data.\n",
    "        \"\"\"\n",
    "        mean, std = self.inference_net.inference(data=data)\n",
    "        mean = mx.sym.tile(data=mean, reps=(n, 1))\n",
    "        std = mx.sym.tile(data=std, reps=(n, 1))\n",
    "        latent_state = self.inference_net.sample_latent_state(mean, std, n)\n",
    "        return self.generator.generate_sample(latent_state=latent_state)\n",
    "\n",
    "    def phantasize(self, n: int) -> mx.sym.Symbol:\n",
    "        \"\"\"\n",
    "        Generate data by randomly sampling from the prior.\n",
    "\n",
    "        :param n: Number of sampled data points.\n",
    "        :return: Randomly generated data points.\n",
    "        \"\"\"\n",
    "        latent_state = mx.sym.random_normal(loc=0, scale=1, shape=(n, self.inference_net.latent_var_size))\n",
    "        return self.generator.generate_sample(latent_state=latent_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a VAE\n",
    "\n",
    "We have now all the code for VAEs in place. Below, we have defined a factory method that makes it easier for you to play with different architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_vae(latent_type: str,\n",
    "                  likelihood: str,\n",
    "                  generator_layer_sizes: List[int],\n",
    "                  infer_layer_sizes: List[int],\n",
    "                  latent_variable_size: int,\n",
    "                  data_dims: int,\n",
    "                  generator_act_type: str = \"tanh\",\n",
    "                  infer_act_type: str = \"tanh\") -> VAE:\n",
    "    \"\"\"\n",
    "    Construct a variational autoencoder\n",
    "\n",
    "    :param latent_type: Distribution of latent variable.\n",
    "    :param likelihood: Type of likelihood.\n",
    "    :param generator_layer_sizes: Sizes of generator hidden layers.\n",
    "    :param infer_layer_size: Sizes of inference network hidden layers.\n",
    "    :param latent_variable_size: Size of the latent variable.\n",
    "    :param data_dims: Dimensionality of the data.\n",
    "    :param generator_act_type: Activation function for generator hidden layers.\n",
    "    :param infer_act_type: Activation function for inference network hidden layers.\n",
    "    :return: A variational autoencoder.\n",
    "    \"\"\"\n",
    "    if likelihood == \"bernoulliProd\":\n",
    "        generator = ProductOfBernoullisGenerator(data_dims=data_dims, layer_sizes=generator_layer_sizes,\n",
    "                                                 act_type=generator_act_type)\n",
    "    else:\n",
    "        raise Exception(\"{} is an invalid likelihood type.\".format(likelihood))\n",
    "\n",
    "    if latent_type == \"gaussian\":\n",
    "        inference_net = GaussianInferenceNetwork(latent_variable_size=latent_variable_size,\n",
    "                                                 layer_sizes=infer_layer_sizes,\n",
    "                                                 act_type=infer_act_type)\n",
    "    else:\n",
    "        raise Exception(\"{} is an invalid latent variable type.\".format(latent_type))\n",
    "        \n",
    "    return GaussianVAE(generator=generator, inference_net=inference_net, kl_divergence=diagonal_gaussian_kl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "\n",
    "Your turn! Construct your own VAE below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = construct_vae(latent_type=\"gaussian\", likelihood=\"bernoulliProd\", generator_layer_sizes=[200,500],\n",
    "                   infer_layer_sizes=[500,200], latent_variable_size=200, data_dims=784, generator_act_type=\"tanh\",\n",
    "                   infer_act_type=\"tanh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check what your VAE looks like we will visualise it. The variables are \"data\" and \"label\" are unbound variables in the computation graph. We will shortly use them to supply data to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: plot Pages: 1 -->\n",
       "<svg width=\"606pt\" height=\"2134pt\"\n",
       " viewBox=\"0.00 0.00 606.00 2134.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 2130)\">\n",
       "<title>plot</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-2130 602,-2130 602,4 -4,4\"/>\n",
       "<!-- label -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>label</title>\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"#000000\" cx=\"159\" cy=\"-1439\" rx=\"47\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-1435.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">label</text>\n",
       "</g>\n",
       "<!-- data -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>data</title>\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"#000000\" cx=\"419\" cy=\"-29\" rx=\"47\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"419\" y=\"-25.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- inf_joint_fc -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>inf_joint_fc</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"#000000\" points=\"466,-152 372,-152 372,-94 466,-94 466,-152\"/>\n",
       "<text text-anchor=\"middle\" x=\"419\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"419\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">500</text>\n",
       "</g>\n",
       "<!-- inf_joint_fc&#45;&gt;data -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>inf_joint_fc&#45;&gt;data</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M419,-83.6321C419,-75.1148 419,-66.2539 419,-58.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"419,-93.7731 414.5001,-83.773 419,-88.7731 419.0001,-83.7731 419.0001,-83.7731 419.0001,-83.7731 419,-88.7731 423.5001,-83.7731 419,-93.7731 419,-93.7731\"/>\n",
       "</g>\n",
       "<!-- inf_joint_act -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>inf_joint_act</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"#000000\" points=\"466,-246 372,-246 372,-188 466,-188 466,-246\"/>\n",
       "<text text-anchor=\"middle\" x=\"419\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"419\" y=\"-205.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">tanh</text>\n",
       "</g>\n",
       "<!-- inf_joint_act&#45;&gt;inf_joint_fc -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>inf_joint_act&#45;&gt;inf_joint_fc</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M419,-177.6321C419,-169.1148 419,-160.2539 419,-152.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"419,-187.7731 414.5001,-177.773 419,-182.7731 419.0001,-177.7731 419.0001,-177.7731 419.0001,-177.7731 419,-182.7731 423.5001,-177.7731 419,-187.7731 419,-187.7731\"/>\n",
       "</g>\n",
       "<!-- FC_m_0 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>FC_m_0</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"#000000\" points=\"411,-434 317,-434 317,-376 411,-376 411,-434\"/>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-408.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-393.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">200</text>\n",
       "</g>\n",
       "<!-- FC_m_0&#45;&gt;inf_joint_act -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>FC_m_0&#45;&gt;inf_joint_act</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M375.4018,-366.0267C385.8374,-330.3558 401.0466,-278.3681 410.4666,-246.1687\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"372.5938,-375.625 371.0827,-364.7637 373.9977,-370.8261 375.4017,-366.0273 375.4017,-366.0273 375.4017,-366.0273 373.9977,-370.8261 379.7206,-367.2908 372.5938,-375.625 372.5938,-375.625\"/>\n",
       "</g>\n",
       "<!-- Act_m_0 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>Act_m_0</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"#000000\" points=\"411,-622 317,-622 317,-564 411,-564 411,-622\"/>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-596.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-581.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">tanh</text>\n",
       "</g>\n",
       "<!-- Act_m_0&#45;&gt;FC_m_0 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>Act_m_0&#45;&gt;FC_m_0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M364,-553.5685C364,-517.9118 364,-466.2305 364,-434.1687\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"364,-563.625 359.5001,-553.625 364,-558.625 364.0001,-553.625 364.0001,-553.625 364.0001,-553.625 364,-558.625 368.5001,-553.625 364,-563.625 364,-563.625\"/>\n",
       "</g>\n",
       "<!-- inf_mean_compute -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>inf_mean_compute</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"#000000\" points=\"411,-716 317,-716 317,-658 411,-658 411,-716\"/>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-690.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-675.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">200</text>\n",
       "</g>\n",
       "<!-- inf_mean_compute&#45;&gt;Act_m_0 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>inf_mean_compute&#45;&gt;Act_m_0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M364,-647.6321C364,-639.1148 364,-630.2539 364,-622.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"364,-657.7731 359.5001,-647.773 364,-652.7731 364.0001,-647.7731 364.0001,-647.7731 364.0001,-647.7731 364,-652.7731 368.5001,-647.7731 364,-657.7731 364,-657.7731\"/>\n",
       "</g>\n",
       "<!-- FC_v_0 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>FC_v_0</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"#000000\" points=\"513,-340 419,-340 419,-282 513,-282 513,-340\"/>\n",
       "<text text-anchor=\"middle\" x=\"466\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"466\" y=\"-299.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">200</text>\n",
       "</g>\n",
       "<!-- FC_v_0&#45;&gt;inf_joint_act -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>FC_v_0&#45;&gt;inf_joint_act</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M446.8766,-272.7532C442.4477,-263.8954 437.8038,-254.6075 433.6044,-246.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"451.3865,-281.7731 442.8894,-274.8413 449.1504,-277.3009 446.9144,-272.8288 446.9144,-272.8288 446.9144,-272.8288 449.1504,-277.3009 450.9393,-270.8163 451.3865,-281.7731 451.3865,-281.7731\"/>\n",
       "</g>\n",
       "<!-- Act_v_0 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>Act_v_0</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"#000000\" points=\"523,-434 429,-434 429,-376 523,-376 523,-434\"/>\n",
       "<text text-anchor=\"middle\" x=\"476\" y=\"-408.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"476\" y=\"-393.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">tanh</text>\n",
       "</g>\n",
       "<!-- Act_v_0&#45;&gt;FC_v_0 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>Act_v_0&#45;&gt;FC_v_0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M471.8119,-365.6321C470.9058,-357.1148 469.9632,-348.2539 469.1073,-340.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"472.8908,-375.7731 467.3581,-366.3053 472.3618,-370.8011 471.8328,-365.8292 471.8328,-365.8292 471.8328,-365.8292 472.3618,-370.8011 476.3076,-365.3531 472.8908,-375.7731 472.8908,-375.7731\"/>\n",
       "</g>\n",
       "<!-- var_compute -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>var_compute</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"#000000\" points=\"523,-528 429,-528 429,-470 523,-470 523,-528\"/>\n",
       "<text text-anchor=\"middle\" x=\"476\" y=\"-502.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"476\" y=\"-487.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">200</text>\n",
       "</g>\n",
       "<!-- var_compute&#45;&gt;Act_v_0 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>var_compute&#45;&gt;Act_v_0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M476,-459.6321C476,-451.1148 476,-442.2539 476,-434.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"476,-469.7731 471.5001,-459.773 476,-464.7731 476.0001,-459.7731 476.0001,-459.7731 476.0001,-459.7731 476,-464.7731 480.5001,-459.7731 476,-469.7731 476,-469.7731\"/>\n",
       "</g>\n",
       "<!-- softrelu_ -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>softrelu_</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"#000000\" points=\"523,-622 429,-622 429,-564 523,-564 523,-622\"/>\n",
       "<text text-anchor=\"middle\" x=\"476\" y=\"-596.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"476\" y=\"-581.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">softrelu</text>\n",
       "</g>\n",
       "<!-- softrelu_&#45;&gt;var_compute -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>softrelu_&#45;&gt;var_compute</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M476,-553.6321C476,-545.1148 476,-536.2539 476,-528.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"476,-563.7731 471.5001,-553.773 476,-558.7731 476.0001,-553.7731 476.0001,-553.7731 476.0001,-553.7731 476,-558.7731 480.5001,-553.7731 476,-563.7731 476,-563.7731\"/>\n",
       "</g>\n",
       "<!-- random_normal25 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>random_normal25</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"299,-622 205,-622 205,-564 299,-564 299,-622\"/>\n",
       "<text text-anchor=\"middle\" x=\"252\" y=\"-589.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">random_normal25</text>\n",
       "</g>\n",
       "<!-- _mul46 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>_mul46</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"299,-716 205,-716 205,-658 299,-658 299,-716\"/>\n",
       "<text text-anchor=\"middle\" x=\"252\" y=\"-683.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_mul46</text>\n",
       "</g>\n",
       "<!-- _mul46&#45;&gt;softrelu_ -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>_mul46&#45;&gt;softrelu_</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M308.4205,-658.0933C358.1278,-638.3042 374.4626,-640.9538 420,-622 422.9313,-620.7799 425.9171,-619.4641 428.9074,-618.0899\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"299.0926,-661.9101 306.6436,-653.9582 303.7202,-660.0166 308.3478,-658.123 308.3478,-658.123 308.3478,-658.123 303.7202,-660.0166 310.0519,-662.2879 299.0926,-661.9101 299.0926,-661.9101\"/>\n",
       "</g>\n",
       "<!-- _mul46&#45;&gt;random_normal25 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>_mul46&#45;&gt;random_normal25</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M252,-647.6321C252,-639.1148 252,-630.2539 252,-622.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"252,-657.7731 247.5001,-647.773 252,-652.7731 252.0001,-647.7731 252.0001,-647.7731 252.0001,-647.7731 252,-652.7731 256.5001,-647.7731 252,-657.7731 252,-657.7731\"/>\n",
       "</g>\n",
       "<!-- _plus62 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>_plus62</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"299,-810 205,-810 205,-752 299,-752 299,-810\"/>\n",
       "<text text-anchor=\"middle\" x=\"252\" y=\"-777.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_plus62</text>\n",
       "</g>\n",
       "<!-- _plus62&#45;&gt;inf_mean_compute -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>_plus62&#45;&gt;inf_mean_compute</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M294.5862,-745.258C306.0184,-735.6631 318.243,-725.4032 329.198,-716.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"286.8236,-751.7731 291.5904,-741.8974 290.6534,-748.5587 294.4833,-745.3443 294.4833,-745.3443 294.4833,-745.3443 290.6534,-748.5587 297.3763,-748.7912 286.8236,-751.7731 286.8236,-751.7731\"/>\n",
       "</g>\n",
       "<!-- _plus62&#45;&gt;_mul46 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>_plus62&#45;&gt;_mul46</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M252,-741.6321C252,-733.1148 252,-724.2539 252,-716.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"252,-751.7731 247.5001,-741.773 252,-746.7731 252.0001,-741.7731 252.0001,-741.7731 252.0001,-741.7731 252,-746.7731 256.5001,-741.7731 252,-751.7731 252,-751.7731\"/>\n",
       "</g>\n",
       "<!-- gen_FC0 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>gen_FC0</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"#000000\" points=\"299,-904 205,-904 205,-846 299,-846 299,-904\"/>\n",
       "<text text-anchor=\"middle\" x=\"252\" y=\"-878.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"252\" y=\"-863.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">200</text>\n",
       "</g>\n",
       "<!-- gen_FC0&#45;&gt;_plus62 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>gen_FC0&#45;&gt;_plus62</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M252,-835.6321C252,-827.1148 252,-818.2539 252,-810.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"252,-845.7731 247.5001,-835.773 252,-840.7731 252.0001,-835.7731 252.0001,-835.7731 252.0001,-835.7731 252,-840.7731 256.5001,-835.7731 252,-845.7731 252,-845.7731\"/>\n",
       "</g>\n",
       "<!-- gen_Act0 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>gen_Act0</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"#000000\" points=\"299,-998 205,-998 205,-940 299,-940 299,-998\"/>\n",
       "<text text-anchor=\"middle\" x=\"252\" y=\"-972.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"252\" y=\"-957.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">tanh</text>\n",
       "</g>\n",
       "<!-- gen_Act0&#45;&gt;gen_FC0 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>gen_Act0&#45;&gt;gen_FC0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M252,-929.6321C252,-921.1148 252,-912.2539 252,-904.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"252,-939.7731 247.5001,-929.773 252,-934.7731 252.0001,-929.7731 252.0001,-929.7731 252.0001,-929.7731 252,-934.7731 256.5001,-929.7731 252,-939.7731 252,-939.7731\"/>\n",
       "</g>\n",
       "<!-- gen_FC1 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>gen_FC1</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"#000000\" points=\"299,-1092 205,-1092 205,-1034 299,-1034 299,-1092\"/>\n",
       "<text text-anchor=\"middle\" x=\"252\" y=\"-1066.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"252\" y=\"-1051.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">500</text>\n",
       "</g>\n",
       "<!-- gen_FC1&#45;&gt;gen_Act0 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>gen_FC1&#45;&gt;gen_Act0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M252,-1023.6321C252,-1015.1148 252,-1006.2539 252,-998.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"252,-1033.7731 247.5001,-1023.773 252,-1028.7731 252.0001,-1023.7731 252.0001,-1023.7731 252.0001,-1023.7731 252,-1028.7731 256.5001,-1023.7731 252,-1033.7731 252,-1033.7731\"/>\n",
       "</g>\n",
       "<!-- gen_Act1 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>gen_Act1</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"#000000\" points=\"299,-1186 205,-1186 205,-1128 299,-1128 299,-1186\"/>\n",
       "<text text-anchor=\"middle\" x=\"252\" y=\"-1160.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"252\" y=\"-1145.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">tanh</text>\n",
       "</g>\n",
       "<!-- gen_Act1&#45;&gt;gen_FC1 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>gen_Act1&#45;&gt;gen_FC1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M252,-1117.6321C252,-1109.1148 252,-1100.2539 252,-1092.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"252,-1127.7731 247.5001,-1117.773 252,-1122.7731 252.0001,-1117.7731 252.0001,-1117.7731 252.0001,-1117.7731 252,-1122.7731 256.5001,-1117.7731 252,-1127.7731 252,-1127.7731\"/>\n",
       "</g>\n",
       "<!-- gen_fc_out -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>gen_fc_out</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"#000000\" points=\"299,-1280 205,-1280 205,-1222 299,-1222 299,-1280\"/>\n",
       "<text text-anchor=\"middle\" x=\"252\" y=\"-1254.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"252\" y=\"-1239.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">784</text>\n",
       "</g>\n",
       "<!-- gen_fc_out&#45;&gt;gen_Act1 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>gen_fc_out&#45;&gt;gen_Act1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M252,-1211.6321C252,-1203.1148 252,-1194.2539 252,-1186.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"252,-1221.7731 247.5001,-1211.773 252,-1216.7731 252.0001,-1211.7731 252.0001,-1211.7731 252.0001,-1211.7731 252,-1216.7731 256.5001,-1211.7731 252,-1221.7731 252,-1221.7731\"/>\n",
       "</g>\n",
       "<!-- output_act -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>output_act</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"#000000\" points=\"299,-1374 205,-1374 205,-1316 299,-1316 299,-1374\"/>\n",
       "<text text-anchor=\"middle\" x=\"252\" y=\"-1348.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"252\" y=\"-1333.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">sigmoid</text>\n",
       "</g>\n",
       "<!-- output_act&#45;&gt;gen_fc_out -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>output_act&#45;&gt;gen_fc_out</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M252,-1305.6321C252,-1297.1148 252,-1288.2539 252,-1280.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"252,-1315.7731 247.5001,-1305.773 252,-1310.7731 252.0001,-1305.7731 252.0001,-1305.7731 252.0001,-1305.7731 252,-1310.7731 256.5001,-1305.7731 252,-1315.7731 252,-1315.7731\"/>\n",
       "</g>\n",
       "<!-- log44 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>log44</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"94,-1468 0,-1468 0,-1410 94,-1410 94,-1468\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-1435.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">log44</text>\n",
       "</g>\n",
       "<!-- log44&#45;&gt;output_act -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>log44&#45;&gt;output_act</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M103.6468,-1409.7832C142.4573,-1391.4401 177.6779,-1376.1411 204.9976,-1364.5578\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"94.2456,-1414.2532 101.3444,-1405.8951 98.7612,-1412.1062 103.2767,-1409.9591 103.2767,-1409.9591 103.2767,-1409.9591 98.7612,-1412.1062 105.2091,-1414.0231 94.2456,-1414.2532 94.2456,-1414.2532\"/>\n",
       "</g>\n",
       "<!-- _mul47 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>_mul47</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"94,-1562 0,-1562 0,-1504 94,-1504 94,-1562\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-1529.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_mul47</text>\n",
       "</g>\n",
       "<!-- _mul47&#45;&gt;label -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>_mul47&#45;&gt;label</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M89.7841,-1497.0919C103.5734,-1485.5188 118.4964,-1472.9941 130.9432,-1462.5477\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"81.8236,-1503.7731 86.5904,-1493.8974 85.6534,-1500.5587 89.4833,-1497.3443 89.4833,-1497.3443 89.4833,-1497.3443 85.6534,-1500.5587 92.3763,-1500.7912 81.8236,-1503.7731 81.8236,-1503.7731\"/>\n",
       "</g>\n",
       "<!-- _mul47&#45;&gt;log44 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>_mul47&#45;&gt;log44</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47,-1493.6321C47,-1485.1148 47,-1476.2539 47,-1468.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"47,-1503.7731 42.5001,-1493.773 47,-1498.7731 47.0001,-1493.7731 47.0001,-1493.7731 47.0001,-1493.7731 47,-1498.7731 51.5001,-1493.7731 47,-1503.7731 47,-1503.7731\"/>\n",
       "</g>\n",
       "<!-- _rminusscalar28 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>_rminusscalar28</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"206,-1562 112,-1562 112,-1504 206,-1504 206,-1562\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-1529.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_rminusscalar28</text>\n",
       "</g>\n",
       "<!-- _rminusscalar28&#45;&gt;label -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>_rminusscalar28&#45;&gt;label</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M159,-1493.6321C159,-1485.1148 159,-1476.2539 159,-1468.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159,-1503.7731 154.5001,-1493.773 159,-1498.7731 159.0001,-1493.7731 159.0001,-1493.7731 159.0001,-1493.7731 159,-1498.7731 163.5001,-1493.7731 159,-1503.7731 159,-1503.7731\"/>\n",
       "</g>\n",
       "<!-- _rminusscalar29 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>_rminusscalar29</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"318,-1468 224,-1468 224,-1410 318,-1410 318,-1468\"/>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-1435.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_rminusscalar29</text>\n",
       "</g>\n",
       "<!-- _rminusscalar29&#45;&gt;output_act -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>_rminusscalar29&#45;&gt;output_act</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M263.0994,-1399.9128C261.3605,-1391.3096 259.5479,-1382.3423 257.9039,-1374.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"265.0924,-1409.7731 258.7003,-1400.8629 264.1018,-1404.8722 263.1111,-1399.9713 263.1111,-1399.9713 263.1111,-1399.9713 264.1018,-1404.8722 267.5219,-1399.0797 265.0924,-1409.7731 265.0924,-1409.7731\"/>\n",
       "</g>\n",
       "<!-- log45 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>log45</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"318,-1562 224,-1562 224,-1504 318,-1504 318,-1562\"/>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-1529.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">log45</text>\n",
       "</g>\n",
       "<!-- log45&#45;&gt;_rminusscalar29 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>log45&#45;&gt;_rminusscalar29</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M271,-1493.6321C271,-1485.1148 271,-1476.2539 271,-1468.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"271,-1503.7731 266.5001,-1493.773 271,-1498.7731 271.0001,-1493.7731 271.0001,-1493.7731 271.0001,-1493.7731 271,-1498.7731 275.5001,-1493.7731 271,-1503.7731 271,-1503.7731\"/>\n",
       "</g>\n",
       "<!-- _mul48 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>_mul48</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"206,-1656 112,-1656 112,-1598 206,-1598 206,-1656\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-1623.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_mul48</text>\n",
       "</g>\n",
       "<!-- _mul48&#45;&gt;_rminusscalar28 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>_mul48&#45;&gt;_rminusscalar28</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M159,-1587.6321C159,-1579.1148 159,-1570.2539 159,-1562.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159,-1597.7731 154.5001,-1587.773 159,-1592.7731 159.0001,-1587.7731 159.0001,-1587.7731 159.0001,-1587.7731 159,-1592.7731 163.5001,-1587.7731 159,-1597.7731 159,-1597.7731\"/>\n",
       "</g>\n",
       "<!-- _mul48&#45;&gt;log45 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>_mul48&#45;&gt;log45</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M201.5862,-1591.258C213.0184,-1581.6631 225.243,-1571.4032 236.198,-1562.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"193.8236,-1597.7731 198.5904,-1587.8974 197.6534,-1594.5587 201.4833,-1591.3443 201.4833,-1591.3443 201.4833,-1591.3443 197.6534,-1594.5587 204.3763,-1594.7912 193.8236,-1597.7731 193.8236,-1597.7731\"/>\n",
       "</g>\n",
       "<!-- _plus65 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>_plus65</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"150,-1750 56,-1750 56,-1692 150,-1692 150,-1750\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-1717.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_plus65</text>\n",
       "</g>\n",
       "<!-- _plus65&#45;&gt;_mul47 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>_plus65&#45;&gt;_mul47</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M91.3909,-1682.0267C80.7656,-1646.3558 65.2799,-1594.3681 55.6886,-1562.1687\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"94.25,-1691.625 87.0824,-1683.3258 92.8226,-1686.8331 91.3952,-1682.0411 91.3952,-1682.0411 91.3952,-1682.0411 92.8226,-1686.8331 95.7079,-1680.7565 94.25,-1691.625 94.25,-1691.625\"/>\n",
       "</g>\n",
       "<!-- _plus65&#45;&gt;_mul48 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>_plus65&#45;&gt;_mul48</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M125.6188,-1683.0328C130.9458,-1674.091 136.5429,-1664.6959 141.599,-1656.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"120.4118,-1691.7731 121.6639,-1680.8789 122.9708,-1687.4776 125.5299,-1683.1821 125.5299,-1683.1821 125.5299,-1683.1821 122.9708,-1687.4776 129.3958,-1685.4852 120.4118,-1691.7731 120.4118,-1691.7731\"/>\n",
       "</g>\n",
       "<!-- sum30 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>sum30</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"150,-1844 56,-1844 56,-1786 150,-1786 150,-1844\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-1811.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">sum30</text>\n",
       "</g>\n",
       "<!-- sum30&#45;&gt;_plus65 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>sum30&#45;&gt;_plus65</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M103,-1775.6321C103,-1767.1148 103,-1758.2539 103,-1750.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103,-1785.7731 98.5001,-1775.773 103,-1780.7731 103.0001,-1775.7731 103.0001,-1775.7731 103.0001,-1775.7731 103,-1780.7731 107.5001,-1775.7731 103,-1785.7731 103,-1785.7731\"/>\n",
       "</g>\n",
       "<!-- _mulscalar55 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>_mulscalar55</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"150,-1938 56,-1938 56,-1880 150,-1880 150,-1938\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-1905.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_mulscalar55</text>\n",
       "</g>\n",
       "<!-- _mulscalar55&#45;&gt;sum30 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>_mulscalar55&#45;&gt;sum30</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M103,-1869.6321C103,-1861.1148 103,-1852.2539 103,-1844.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103,-1879.7731 98.5001,-1869.773 103,-1874.7731 103.0001,-1869.7731 103.0001,-1869.7731 103.0001,-1869.7731 103,-1874.7731 107.5001,-1869.7731 103,-1879.7731 103,-1879.7731\"/>\n",
       "</g>\n",
       "<!-- makeloss17 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>makeloss17</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"150,-2032 56,-2032 56,-1974 150,-1974 150,-2032\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-1999.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">makeloss17</text>\n",
       "</g>\n",
       "<!-- makeloss17&#45;&gt;_mulscalar55 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>makeloss17&#45;&gt;_mulscalar55</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M103,-1963.6321C103,-1955.1148 103,-1946.2539 103,-1938.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103,-1973.7731 98.5001,-1963.773 103,-1968.7731 103.0001,-1963.7731 103.0001,-1963.7731 103.0001,-1963.7731 103,-1968.7731 107.5001,-1963.7731 103,-1973.7731 103,-1973.7731\"/>\n",
       "</g>\n",
       "<!-- _mulscalar56 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>_mulscalar56</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"150,-2126 56,-2126 56,-2068 150,-2068 150,-2126\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-2093.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_mulscalar56</text>\n",
       "</g>\n",
       "<!-- _mulscalar56&#45;&gt;makeloss17 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>_mulscalar56&#45;&gt;makeloss17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M103,-2057.6321C103,-2049.1148 103,-2040.2539 103,-2032.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103,-2067.7731 98.5001,-2057.773 103,-2062.7731 103.0001,-2057.7731 103.0001,-2057.7731 103.0001,-2057.7731 103,-2062.7731 107.5001,-2057.7731 103,-2067.7731 103,-2067.7731\"/>\n",
       "</g>\n",
       "<!-- _powerscalar45 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>_powerscalar45</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"584,-716 490,-716 490,-658 584,-658 584,-716\"/>\n",
       "<text text-anchor=\"middle\" x=\"537\" y=\"-683.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_powerscalar45</text>\n",
       "</g>\n",
       "<!-- _powerscalar45&#45;&gt;softrelu_ -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>_powerscalar45&#45;&gt;softrelu_</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M512.5429,-649.3121C506.6861,-640.2868 500.5196,-630.7843 494.9547,-622.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"518.0336,-657.7731 508.8151,-651.8342 515.3118,-653.5788 512.5899,-649.3846 512.5899,-649.3846 512.5899,-649.3846 515.3118,-653.5788 516.3648,-646.9349 518.0336,-657.7731 518.0336,-657.7731\"/>\n",
       "</g>\n",
       "<!-- log43 -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>log43</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"588,-810 494,-810 494,-752 588,-752 588,-810\"/>\n",
       "<text text-anchor=\"middle\" x=\"541\" y=\"-777.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">log43</text>\n",
       "</g>\n",
       "<!-- log43&#45;&gt;_powerscalar45 -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>log43&#45;&gt;_powerscalar45</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M539.3248,-741.6321C538.9623,-733.1148 538.5853,-724.2539 538.2429,-716.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"539.7563,-751.7731 534.8351,-741.9735 539.5437,-746.7776 539.3311,-741.7821 539.3311,-741.7821 539.3311,-741.7821 539.5437,-746.7776 543.827,-741.5908 539.7563,-751.7731 539.7563,-751.7731\"/>\n",
       "</g>\n",
       "<!-- _mulscalar53 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>_mulscalar53</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"598,-904 504,-904 504,-846 598,-846 598,-904\"/>\n",
       "<text text-anchor=\"middle\" x=\"551\" y=\"-871.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_mulscalar53</text>\n",
       "</g>\n",
       "<!-- _mulscalar53&#45;&gt;log43 -->\n",
       "<g id=\"edge36\" class=\"edge\">\n",
       "<title>_mulscalar53&#45;&gt;log43</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M546.8119,-835.6321C545.9058,-827.1148 544.9632,-818.2539 544.1073,-810.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"547.8908,-845.7731 542.3581,-836.3053 547.3618,-840.8011 546.8328,-835.8292 546.8328,-835.8292 546.8328,-835.8292 547.3618,-840.8011 551.3076,-835.3531 547.8908,-845.7731 547.8908,-845.7731\"/>\n",
       "</g>\n",
       "<!-- _minusscalar15 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>_minusscalar15</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"579,-998 485,-998 485,-940 579,-940 579,-998\"/>\n",
       "<text text-anchor=\"middle\" x=\"532\" y=\"-965.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_minusscalar15</text>\n",
       "</g>\n",
       "<!-- _minusscalar15&#45;&gt;_mulscalar53 -->\n",
       "<g id=\"edge37\" class=\"edge\">\n",
       "<title>_minusscalar15&#45;&gt;_mulscalar53</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M539.9006,-929.9128C541.6395,-921.3096 543.4521,-912.3423 545.0961,-904.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"537.9076,-939.7731 535.4781,-929.0797 538.8982,-934.8722 539.8889,-929.9713 539.8889,-929.9713 539.8889,-929.9713 538.8982,-934.8722 544.2997,-930.8629 537.9076,-939.7731 537.9076,-939.7731\"/>\n",
       "</g>\n",
       "<!-- _powerscalar46 -->\n",
       "<g id=\"node36\" class=\"node\">\n",
       "<title>_powerscalar46</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"486,-904 392,-904 392,-846 486,-846 486,-904\"/>\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-871.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_powerscalar46</text>\n",
       "</g>\n",
       "<!-- _powerscalar46&#45;&gt;softrelu_ -->\n",
       "<g id=\"edge38\" class=\"edge\">\n",
       "<title>_powerscalar46&#45;&gt;softrelu_</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M444.1461,-835.7787C451.6546,-778.5514 465.4459,-673.4395 472.1451,-622.3809\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"442.8203,-845.8832 439.6595,-835.3827 443.4708,-840.9257 444.1213,-835.9682 444.1213,-835.9682 444.1213,-835.9682 443.4708,-840.9257 448.583,-836.5536 442.8203,-845.8832 442.8203,-845.8832\"/>\n",
       "</g>\n",
       "<!-- _plus63 -->\n",
       "<g id=\"node37\" class=\"node\">\n",
       "<title>_plus63</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"486,-1092 392,-1092 392,-1034 486,-1034 486,-1092\"/>\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-1059.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_plus63</text>\n",
       "</g>\n",
       "<!-- _plus63&#45;&gt;_minusscalar15 -->\n",
       "<g id=\"edge39\" class=\"edge\">\n",
       "<title>_plus63&#45;&gt;_minusscalar15</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M475.1848,-1026.4261C484.4393,-1017.0721 494.2678,-1007.138 503.1019,-998.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"467.916,-1033.7731 471.7502,-1023.4993 471.4326,-1030.2187 474.9492,-1026.6643 474.9492,-1026.6643 474.9492,-1026.6643 471.4326,-1030.2187 478.1481,-1029.8292 467.916,-1033.7731 467.916,-1033.7731\"/>\n",
       "</g>\n",
       "<!-- _plus63&#45;&gt;_powerscalar46 -->\n",
       "<g id=\"edge40\" class=\"edge\">\n",
       "<title>_plus63&#45;&gt;_powerscalar46</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M439,-1023.5685C439,-987.9118 439,-936.2305 439,-904.1687\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"439,-1033.625 434.5001,-1023.625 439,-1028.625 439.0001,-1023.625 439.0001,-1023.625 439.0001,-1023.625 439,-1028.625 443.5001,-1023.625 439,-1033.625 439,-1033.625\"/>\n",
       "</g>\n",
       "<!-- _powerscalar47 -->\n",
       "<g id=\"node38\" class=\"node\">\n",
       "<title>_powerscalar47</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"411,-998 317,-998 317,-940 411,-940 411,-998\"/>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-965.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_powerscalar47</text>\n",
       "</g>\n",
       "<!-- _powerscalar47&#45;&gt;inf_mean_compute -->\n",
       "<g id=\"edge41\" class=\"edge\">\n",
       "<title>_powerscalar47&#45;&gt;inf_mean_compute</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M364,-929.7787C364,-872.5514 364,-767.4395 364,-716.3809\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"364,-939.8832 359.5001,-929.8831 364,-934.8832 364.0001,-929.8832 364.0001,-929.8832 364.0001,-929.8832 364,-934.8832 368.5001,-929.8832 364,-939.8832 364,-939.8832\"/>\n",
       "</g>\n",
       "<!-- _plus64 -->\n",
       "<g id=\"node39\" class=\"node\">\n",
       "<title>_plus64</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"448,-1186 354,-1186 354,-1128 448,-1128 448,-1186\"/>\n",
       "<text text-anchor=\"middle\" x=\"401\" y=\"-1153.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_plus64</text>\n",
       "</g>\n",
       "<!-- _plus64&#45;&gt;_plus63 -->\n",
       "<g id=\"edge42\" class=\"edge\">\n",
       "<title>_plus64&#45;&gt;_plus63</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M416.5746,-1118.4734C420.1213,-1109.6999 423.8327,-1100.5191 427.1922,-1092.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"412.8151,-1127.7731 412.3911,-1116.8154 414.6891,-1123.1375 416.5631,-1118.502 416.5631,-1118.502 416.5631,-1118.502 414.6891,-1123.1375 420.7351,-1120.1886 412.8151,-1127.7731 412.8151,-1127.7731\"/>\n",
       "</g>\n",
       "<!-- _plus64&#45;&gt;_powerscalar47 -->\n",
       "<g id=\"edge43\" class=\"edge\">\n",
       "<title>_plus64&#45;&gt;_powerscalar47</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M389.4063,-1118.0098C387.0948,-1109.4843 384.8215,-1100.4751 383,-1092 376.1441,-1060.1012 370.7656,-1023.0394 367.5069,-998.0034\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"392.1125,-1127.735 385.0963,-1119.3075 390.7721,-1122.9181 389.4316,-1118.1011 389.4316,-1118.1011 389.4316,-1118.1011 390.7721,-1122.9181 393.7669,-1116.8947 392.1125,-1127.735 392.1125,-1127.735\"/>\n",
       "</g>\n",
       "<!-- sum29 -->\n",
       "<g id=\"node40\" class=\"node\">\n",
       "<title>sum29</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"448,-1280 354,-1280 354,-1222 448,-1222 448,-1280\"/>\n",
       "<text text-anchor=\"middle\" x=\"401\" y=\"-1247.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">sum29</text>\n",
       "</g>\n",
       "<!-- sum29&#45;&gt;_plus64 -->\n",
       "<g id=\"edge44\" class=\"edge\">\n",
       "<title>sum29&#45;&gt;_plus64</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M401,-1211.6321C401,-1203.1148 401,-1194.2539 401,-1186.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"401,-1221.7731 396.5001,-1211.773 401,-1216.7731 401.0001,-1211.7731 401.0001,-1211.7731 401.0001,-1211.7731 401,-1216.7731 405.5001,-1211.7731 401,-1221.7731 401,-1221.7731\"/>\n",
       "</g>\n",
       "<!-- _mulscalar54 -->\n",
       "<g id=\"node41\" class=\"node\">\n",
       "<title>_mulscalar54</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"448,-1374 354,-1374 354,-1316 448,-1316 448,-1374\"/>\n",
       "<text text-anchor=\"middle\" x=\"401\" y=\"-1341.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">_mulscalar54</text>\n",
       "</g>\n",
       "<!-- _mulscalar54&#45;&gt;sum29 -->\n",
       "<g id=\"edge45\" class=\"edge\">\n",
       "<title>_mulscalar54&#45;&gt;sum29</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M401,-1305.6321C401,-1297.1148 401,-1288.2539 401,-1280.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"401,-1315.7731 396.5001,-1305.773 401,-1310.7731 401.0001,-1305.7731 401.0001,-1305.7731 401.0001,-1305.7731 401,-1310.7731 405.5001,-1305.7731 401,-1315.7731 401,-1315.7731\"/>\n",
       "</g>\n",
       "<!-- gaussian_kl_loss -->\n",
       "<g id=\"node42\" class=\"node\">\n",
       "<title>gaussian_kl_loss</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"448,-1468 354,-1468 354,-1410 448,-1410 448,-1468\"/>\n",
       "<text text-anchor=\"middle\" x=\"401\" y=\"-1435.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gaussian_kl_loss</text>\n",
       "</g>\n",
       "<!-- gaussian_kl_loss&#45;&gt;_mulscalar54 -->\n",
       "<g id=\"edge46\" class=\"edge\">\n",
       "<title>gaussian_kl_loss&#45;&gt;_mulscalar54</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M401,-1399.6321C401,-1391.1148 401,-1382.2539 401,-1374.2088\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"401,-1409.7731 396.5001,-1399.773 401,-1404.7731 401.0001,-1399.7731 401.0001,-1399.7731 401.0001,-1399.7731 401,-1404.7731 405.5001,-1399.7731 401,-1409.7731 401,-1409.7731\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fadf6ef92b0>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mx.sym.Variable(\"data\")\n",
    "label = mx.sym.Variable(\"label\")\n",
    "mx.viz.plot_network(vae.train(data, label))\n",
    "# Comment out the line above and uncomment the one below if you want to save the VAE picture on disk\n",
    "#mx.viz.plot_network(vae.train(data, label), title=\"my_vae\", save_format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a VAE\n",
    "\n",
    "We are now set to train the VAE. In order to do so we have to define a data iterator and a module in mxnet. The data iterator takes care of batching the data while the module executes the computation graph and updates the model parameters. For the purpose of training the model, we only need the training data which we load from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:00:08 [INFO]: Reading ./binary_mnist/binary_mnist.train into memory\n",
      "15:01:26 [INFO]: ./binary_mnist/binary_mnist.train contains 50000 data points\n"
     ]
    }
   ],
   "source": [
    "mnist = {}\n",
    "file_name = join(data_dir, \"binary_mnist.{}\".format(TRAIN_SET))\n",
    "logging.info(\"Reading {} into memory\".format(file_name))\n",
    "mnist[TRAIN_SET] = mx.nd.array(np.genfromtxt(file_name))\n",
    "logging.info(\"{} contains {} data points\".format(file_name, mnist[TRAIN_SET].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using that data we define the training set iterator. At this point we also need to choose a batch_size that will then be used in training. Notice that we randomise the order in which the data points are presented in the training set. It is important that `data_name` and `label_name` match the names of the unbound variables in our model. MXNet will use this information to pass the correct data points to the variables. Finally, notice that the data and labels are identical. This is because the VAE tries to reconstruct its input data and thus labels and data are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "train_iter = mx.io.NDArrayIter(data=mnist[TRAIN_SET], data_name=\"data\", label=mnist[TRAIN_SET], label_name=\"label\",\n",
    "                                   batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a module that will do the training for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_module = mx.module.Module(vae.train(data=mx.sym.Variable(\"data\"), label=mx.sym.Variable(\"label\")),\n",
    "                           data_names=[train_iter.provide_data[0][0]],\n",
    "                           label_names=[train_iter.provide_label[0][0]], context=ctx, logger=logging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the vae (or any other network defined in mxnet) is most easily done using the [fit method](https://mxnet.incubator.apache.org/api/python/module/module.html#mxnet.module.BaseModule.fit). Here we choose to train our model for 20 epochs. Our optimiser will be adam. Training will take some time (approximately 2-5 minutes, depending on your machine). We are keeping track of the loss (the negative ELBO) to see how the model develops. Notice that this loss\n",
    "is not the actual negative ELBO but a _doubly stochastic approximation_ to it (see [here](https://projecteuclid.org/download/pdf_1/euclid.aoms/1177729586) and [here](http://proceedings.mlr.press/v32/titsias14.pdf)). The two sources of stochasticity are the mini-batches (the ELBO is defined with respect to the entire data set) and the Gaussian reparametrisation (we approximate the integral over $ z $ through sampling). Both sources of stochasticity leave the approximation unbiased, however. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElboMetric(mx.metric.EvalMetric):\n",
    "\n",
    "    def __init__(self, name: str = \"elbo\",\n",
    "                 output_names: Optional[List[str]] = None,\n",
    "                 label_names: Optional[List[str]] = None):\n",
    "        super().__init__(name, output_names, label_names)\n",
    "\n",
    "    def update(self, labels: List[mx.nd.array], preds: List[mx.nd.array]):\n",
    "        neg_likelihoods, kl_values, *_ = preds\n",
    "        label = labels[0]\n",
    "        batch_size = label.shape[0]\n",
    "        self.num_inst += batch_size\n",
    "        self.sum_metric += -mx.nd.sum(neg_likelihoods).asscalar() - mx.nd.sum(kl_values).asscalar()\n",
    "\n",
    "\n",
    "class KLMetric(mx.metric.EvalMetric):\n",
    "\n",
    "    def __init__(self, name: str = \"kl_divergence\",\n",
    "                 output_names: Optional[List[str]] = None,\n",
    "                 label_names: Optional[List[str]] = None):\n",
    "        super().__init__(name, output_names, label_names)\n",
    "\n",
    "    def update(self, labels: List[mx.nd.array], preds: List[mx.nd.array]):\n",
    "        neg_likelihoods, kl_values, *_ = preds\n",
    "        label = labels[0]\n",
    "        batch_size = label.shape[0]\n",
    "        self.num_inst += batch_size\n",
    "        self.sum_metric += mx.nd.sum(kl_values).asscalar()\n",
    "        \n",
    "metric = mx.metric.CompositeEvalMetric([ElboMetric(), KLMetric()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:15:24 [INFO]: Epoch[0] Batch [20]\tSpeed: 1673.38 samples/sec\telbo=501.235100\tkl_divergence=16.244448\n",
      "17:15:26 [INFO]: Epoch[0] Batch [40]\tSpeed: 1578.44 samples/sec\telbo=205.857931\tkl_divergence=38.900856\n",
      "17:15:29 [INFO]: Epoch[0] Batch [60]\tSpeed: 1593.04 samples/sec\telbo=204.480165\tkl_divergence=8.902876\n",
      "17:15:31 [INFO]: Epoch[0] Batch [80]\tSpeed: 1641.19 samples/sec\telbo=203.282608\tkl_divergence=6.890034\n",
      "17:15:34 [INFO]: Epoch[0] Batch [100]\tSpeed: 1635.87 samples/sec\telbo=203.363867\tkl_divergence=5.973992\n",
      "17:15:36 [INFO]: Epoch[0] Batch [120]\tSpeed: 1583.58 samples/sec\telbo=202.208934\tkl_divergence=6.036833\n",
      "17:15:39 [INFO]: Epoch[0] Batch [140]\tSpeed: 1547.82 samples/sec\telbo=202.214183\tkl_divergence=6.019698\n",
      "17:15:41 [INFO]: Epoch[0] Batch [160]\tSpeed: 1598.31 samples/sec\telbo=201.679730\tkl_divergence=5.620279\n",
      "17:15:45 [INFO]: Epoch[0] Batch [180]\tSpeed: 1166.06 samples/sec\telbo=201.157113\tkl_divergence=5.926098\n",
      "17:15:47 [INFO]: Epoch[0] Batch [200]\tSpeed: 1418.56 samples/sec\telbo=202.520015\tkl_divergence=6.425163\n",
      "17:15:50 [INFO]: Epoch[0] Batch [220]\tSpeed: 1431.65 samples/sec\telbo=200.762053\tkl_divergence=6.105053\n",
      "17:15:53 [INFO]: Epoch[0] Batch [240]\tSpeed: 1583.21 samples/sec\telbo=202.460818\tkl_divergence=5.129356\n",
      "17:15:54 [INFO]: Epoch[0] Train-elbo=199.001272\n",
      "17:15:54 [INFO]: Epoch[0] Train-kl_divergence=7.324255\n",
      "17:15:54 [INFO]: Epoch[0] Time cost=32.923\n",
      "17:15:54 [INFO]: Saved checkpoint to \"vae-0001.params\"\n",
      "17:15:57 [INFO]: Epoch[1] Batch [20]\tSpeed: 1602.47 samples/sec\telbo=198.871270\tkl_divergence=5.881805\n",
      "17:15:59 [INFO]: Epoch[1] Batch [40]\tSpeed: 1590.88 samples/sec\telbo=200.462944\tkl_divergence=5.699620\n",
      "17:16:02 [INFO]: Epoch[1] Batch [60]\tSpeed: 1603.91 samples/sec\telbo=201.206634\tkl_divergence=5.997607\n",
      "17:16:04 [INFO]: Epoch[1] Batch [80]\tSpeed: 1594.63 samples/sec\telbo=201.629070\tkl_divergence=5.413764\n",
      "17:16:07 [INFO]: Epoch[1] Batch [100]\tSpeed: 1612.72 samples/sec\telbo=201.138702\tkl_divergence=5.726916\n",
      "17:16:09 [INFO]: Epoch[1] Batch [120]\tSpeed: 1637.62 samples/sec\telbo=200.670027\tkl_divergence=5.634317\n",
      "17:16:12 [INFO]: Epoch[1] Batch [140]\tSpeed: 1640.21 samples/sec\telbo=201.050326\tkl_divergence=5.082489\n",
      "17:16:14 [INFO]: Epoch[1] Batch [160]\tSpeed: 1632.45 samples/sec\telbo=200.184706\tkl_divergence=5.654314\n",
      "17:16:16 [INFO]: Epoch[1] Batch [180]\tSpeed: 1640.25 samples/sec\telbo=201.420155\tkl_divergence=4.841430\n",
      "17:16:19 [INFO]: Epoch[1] Batch [200]\tSpeed: 1640.00 samples/sec\telbo=202.269783\tkl_divergence=5.725943\n",
      "17:16:21 [INFO]: Epoch[1] Batch [220]\tSpeed: 1640.18 samples/sec\telbo=200.718575\tkl_divergence=5.182004\n",
      "17:16:24 [INFO]: Epoch[1] Batch [240]\tSpeed: 1637.79 samples/sec\telbo=201.714859\tkl_divergence=5.032220\n",
      "17:16:25 [INFO]: Epoch[1] Train-elbo=200.936131\n",
      "17:16:25 [INFO]: Epoch[1] Train-kl_divergence=4.747130\n",
      "17:16:25 [INFO]: Epoch[1] Time cost=30.882\n",
      "17:16:25 [INFO]: Saved checkpoint to \"vae-0002.params\"\n",
      "17:16:28 [INFO]: Epoch[2] Batch [20]\tSpeed: 1643.40 samples/sec\telbo=198.886130\tkl_divergence=5.512973\n",
      "17:16:30 [INFO]: Epoch[2] Batch [40]\tSpeed: 1561.59 samples/sec\telbo=200.577164\tkl_divergence=4.974232\n",
      "17:16:33 [INFO]: Epoch[2] Batch [60]\tSpeed: 1633.10 samples/sec\telbo=201.726459\tkl_divergence=5.142927\n",
      "17:16:35 [INFO]: Epoch[2] Batch [80]\tSpeed: 1637.26 samples/sec\telbo=201.375638\tkl_divergence=5.166122\n",
      "17:16:38 [INFO]: Epoch[2] Batch [100]\tSpeed: 1479.22 samples/sec\telbo=201.583560\tkl_divergence=4.878058\n",
      "17:16:40 [INFO]: Epoch[2] Batch [120]\tSpeed: 1533.87 samples/sec\telbo=201.453023\tkl_divergence=4.654489\n",
      "17:16:43 [INFO]: Epoch[2] Batch [140]\tSpeed: 1543.98 samples/sec\telbo=200.396549\tkl_divergence=5.059579\n",
      "17:16:45 [INFO]: Epoch[2] Batch [160]\tSpeed: 1637.22 samples/sec\telbo=200.533389\tkl_divergence=5.130806\n",
      "17:16:48 [INFO]: Epoch[2] Batch [180]\tSpeed: 1519.62 samples/sec\telbo=200.382656\tkl_divergence=4.925700\n",
      "17:16:51 [INFO]: Epoch[2] Batch [200]\tSpeed: 1573.21 samples/sec\telbo=202.506609\tkl_divergence=5.159086\n",
      "17:16:53 [INFO]: Epoch[2] Batch [220]\tSpeed: 1583.44 samples/sec\telbo=199.428299\tkl_divergence=5.743692\n",
      "17:16:56 [INFO]: Epoch[2] Batch [240]\tSpeed: 1508.66 samples/sec\telbo=200.943302\tkl_divergence=4.395142\n",
      "17:16:57 [INFO]: Epoch[2] Train-elbo=199.934447\n",
      "17:16:57 [INFO]: Epoch[2] Train-kl_divergence=4.898310\n",
      "17:16:57 [INFO]: Epoch[2] Time cost=32.052\n",
      "17:16:57 [INFO]: Saved checkpoint to \"vae-0003.params\"\n",
      "17:17:00 [INFO]: Epoch[3] Batch [20]\tSpeed: 1522.18 samples/sec\telbo=197.932274\tkl_divergence=4.827024\n",
      "17:17:03 [INFO]: Epoch[3] Batch [40]\tSpeed: 1201.07 samples/sec\telbo=199.116831\tkl_divergence=4.503198\n",
      "17:17:06 [INFO]: Epoch[3] Batch [60]\tSpeed: 1241.05 samples/sec\telbo=199.689578\tkl_divergence=4.888999\n",
      "17:17:09 [INFO]: Epoch[3] Batch [80]\tSpeed: 1402.41 samples/sec\telbo=200.225547\tkl_divergence=4.386334\n",
      "17:17:13 [INFO]: Epoch[3] Batch [100]\tSpeed: 1216.13 samples/sec\telbo=198.585920\tkl_divergence=4.648418\n",
      "17:17:16 [INFO]: Epoch[3] Batch [120]\tSpeed: 1156.80 samples/sec\telbo=198.548978\tkl_divergence=4.449077\n",
      "17:17:20 [INFO]: Epoch[3] Batch [140]\tSpeed: 1110.36 samples/sec\telbo=197.234562\tkl_divergence=4.868747\n",
      "17:17:23 [INFO]: Epoch[3] Batch [160]\tSpeed: 1138.92 samples/sec\telbo=196.947305\tkl_divergence=4.197739\n",
      "17:17:27 [INFO]: Epoch[3] Batch [180]\tSpeed: 1099.56 samples/sec\telbo=196.877866\tkl_divergence=4.080944\n",
      "17:17:30 [INFO]: Epoch[3] Batch [200]\tSpeed: 1164.98 samples/sec\telbo=197.751402\tkl_divergence=4.460299\n",
      "17:17:33 [INFO]: Epoch[3] Batch [220]\tSpeed: 1244.36 samples/sec\telbo=194.972223\tkl_divergence=4.619237\n",
      "17:17:37 [INFO]: Epoch[3] Batch [240]\tSpeed: 1128.16 samples/sec\telbo=195.553528\tkl_divergence=4.254515\n",
      "17:17:38 [INFO]: Epoch[3] Train-elbo=194.693110\n",
      "17:17:38 [INFO]: Epoch[3] Train-kl_divergence=3.808031\n",
      "17:17:39 [INFO]: Epoch[3] Time cost=41.468\n",
      "17:17:39 [INFO]: Saved checkpoint to \"vae-0004.params\"\n",
      "17:17:42 [INFO]: Epoch[4] Batch [20]\tSpeed: 1344.90 samples/sec\telbo=191.535352\tkl_divergence=3.978326\n",
      "17:17:45 [INFO]: Epoch[4] Batch [40]\tSpeed: 1286.81 samples/sec\telbo=192.047035\tkl_divergence=3.611337\n",
      "17:17:48 [INFO]: Epoch[4] Batch [60]\tSpeed: 1376.87 samples/sec\telbo=192.407248\tkl_divergence=3.435188\n",
      "17:17:51 [INFO]: Epoch[4] Batch [80]\tSpeed: 1318.20 samples/sec\telbo=191.764413\tkl_divergence=3.262123\n",
      "17:17:54 [INFO]: Epoch[4] Batch [100]\tSpeed: 1300.70 samples/sec\telbo=191.106787\tkl_divergence=2.915105\n",
      "17:17:57 [INFO]: Epoch[4] Batch [120]\tSpeed: 1397.78 samples/sec\telbo=189.885593\tkl_divergence=2.826880\n",
      "17:17:59 [INFO]: Epoch[4] Batch [140]\tSpeed: 1440.71 samples/sec\telbo=189.582608\tkl_divergence=2.646916\n",
      "17:18:02 [INFO]: Epoch[4] Batch [160]\tSpeed: 1395.23 samples/sec\telbo=189.115678\tkl_divergence=2.418921\n",
      "17:18:05 [INFO]: Epoch[4] Batch [180]\tSpeed: 1418.88 samples/sec\telbo=188.971599\tkl_divergence=2.367871\n",
      "17:18:08 [INFO]: Epoch[4] Batch [200]\tSpeed: 1425.47 samples/sec\telbo=190.342781\tkl_divergence=2.287145\n",
      "17:18:11 [INFO]: Epoch[4] Batch [220]\tSpeed: 1420.34 samples/sec\telbo=187.768024\tkl_divergence=2.301588\n",
      "17:18:13 [INFO]: Epoch[4] Batch [240]\tSpeed: 1528.94 samples/sec\telbo=188.904967\tkl_divergence=2.276265\n",
      "17:18:15 [INFO]: Epoch[4] Train-elbo=188.322819\n",
      "17:18:15 [INFO]: Epoch[4] Train-kl_divergence=2.215897\n",
      "17:18:15 [INFO]: Epoch[4] Time cost=36.042\n",
      "17:18:15 [INFO]: Saved checkpoint to \"vae-0005.params\"\n",
      "17:18:17 [INFO]: Epoch[5] Batch [20]\tSpeed: 1512.37 samples/sec\telbo=186.075135\tkl_divergence=2.220205\n",
      "17:18:20 [INFO]: Epoch[5] Batch [40]\tSpeed: 1564.36 samples/sec\telbo=186.950384\tkl_divergence=2.260084\n",
      "17:18:23 [INFO]: Epoch[5] Batch [60]\tSpeed: 1307.61 samples/sec\telbo=188.117474\tkl_divergence=2.220218\n",
      "17:18:26 [INFO]: Epoch[5] Batch [80]\tSpeed: 1455.54 samples/sec\telbo=188.116083\tkl_divergence=2.280795\n",
      "17:18:29 [INFO]: Epoch[5] Batch [100]\tSpeed: 1456.99 samples/sec\telbo=187.609844\tkl_divergence=2.334929\n",
      "17:18:32 [INFO]: Epoch[5] Batch [120]\tSpeed: 1214.59 samples/sec\telbo=186.248127\tkl_divergence=2.477407\n",
      "17:18:34 [INFO]: Epoch[5] Batch [140]\tSpeed: 1537.05 samples/sec\telbo=186.126396\tkl_divergence=2.520658\n",
      "17:18:37 [INFO]: Epoch[5] Batch [160]\tSpeed: 1623.96 samples/sec\telbo=186.026297\tkl_divergence=2.525995\n",
      "17:18:39 [INFO]: Epoch[5] Batch [180]\tSpeed: 1590.57 samples/sec\telbo=185.907173\tkl_divergence=2.602547\n",
      "17:18:42 [INFO]: Epoch[5] Batch [200]\tSpeed: 1632.59 samples/sec\telbo=186.937219\tkl_divergence=2.691780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:18:44 [INFO]: Epoch[5] Batch [220]\tSpeed: 1633.03 samples/sec\telbo=184.371164\tkl_divergence=2.722566\n",
      "17:18:47 [INFO]: Epoch[5] Batch [240]\tSpeed: 1581.61 samples/sec\telbo=185.627439\tkl_divergence=2.725919\n",
      "17:18:48 [INFO]: Epoch[5] Train-elbo=185.001617\n",
      "17:18:48 [INFO]: Epoch[5] Train-kl_divergence=2.691802\n",
      "17:18:48 [INFO]: Epoch[5] Time cost=33.366\n",
      "17:18:48 [INFO]: Saved checkpoint to \"vae-0006.params\"\n",
      "17:18:51 [INFO]: Epoch[6] Batch [20]\tSpeed: 1638.46 samples/sec\telbo=182.725297\tkl_divergence=2.787008\n",
      "17:18:53 [INFO]: Epoch[6] Batch [40]\tSpeed: 1639.03 samples/sec\telbo=183.215915\tkl_divergence=2.877968\n",
      "17:18:56 [INFO]: Epoch[6] Batch [60]\tSpeed: 1636.34 samples/sec\telbo=184.246677\tkl_divergence=2.950512\n",
      "17:18:58 [INFO]: Epoch[6] Batch [80]\tSpeed: 1639.30 samples/sec\telbo=184.468790\tkl_divergence=2.997280\n",
      "17:19:00 [INFO]: Epoch[6] Batch [100]\tSpeed: 1633.34 samples/sec\telbo=183.862165\tkl_divergence=3.103365\n",
      "17:19:03 [INFO]: Epoch[6] Batch [120]\tSpeed: 1615.90 samples/sec\telbo=182.139616\tkl_divergence=3.294312\n",
      "17:19:05 [INFO]: Epoch[6] Batch [140]\tSpeed: 1578.67 samples/sec\telbo=181.864637\tkl_divergence=3.301570\n",
      "17:19:08 [INFO]: Epoch[6] Batch [160]\tSpeed: 1459.51 samples/sec\telbo=181.041029\tkl_divergence=3.442515\n",
      "17:19:11 [INFO]: Epoch[6] Batch [180]\tSpeed: 1359.57 samples/sec\telbo=180.696298\tkl_divergence=3.512950\n",
      "17:19:14 [INFO]: Epoch[6] Batch [200]\tSpeed: 1255.98 samples/sec\telbo=181.296886\tkl_divergence=3.555435\n",
      "17:19:17 [INFO]: Epoch[6] Batch [220]\tSpeed: 1432.56 samples/sec\telbo=178.256203\tkl_divergence=3.710303\n",
      "17:19:20 [INFO]: Epoch[6] Batch [240]\tSpeed: 1208.84 samples/sec\telbo=179.025636\tkl_divergence=3.736359\n",
      "17:19:22 [INFO]: Epoch[6] Train-elbo=177.694564\n",
      "17:19:22 [INFO]: Epoch[6] Train-kl_divergence=3.923640\n",
      "17:19:22 [INFO]: Epoch[6] Time cost=33.826\n",
      "17:19:22 [INFO]: Saved checkpoint to \"vae-0007.params\"\n",
      "17:19:25 [INFO]: Epoch[7] Batch [20]\tSpeed: 1477.48 samples/sec\telbo=176.059904\tkl_divergence=3.837094\n",
      "17:19:28 [INFO]: Epoch[7] Batch [40]\tSpeed: 1427.00 samples/sec\telbo=175.727913\tkl_divergence=4.020560\n",
      "17:19:30 [INFO]: Epoch[7] Batch [60]\tSpeed: 1455.53 samples/sec\telbo=176.980118\tkl_divergence=4.015867\n",
      "17:19:33 [INFO]: Epoch[7] Batch [80]\tSpeed: 1415.00 samples/sec\telbo=177.008210\tkl_divergence=4.029200\n",
      "17:19:36 [INFO]: Epoch[7] Batch [100]\tSpeed: 1241.47 samples/sec\telbo=176.110387\tkl_divergence=4.131618\n",
      "17:19:39 [INFO]: Epoch[7] Batch [120]\tSpeed: 1431.57 samples/sec\telbo=175.197147\tkl_divergence=4.189745\n",
      "17:19:42 [INFO]: Epoch[7] Batch [140]\tSpeed: 1530.24 samples/sec\telbo=175.247660\tkl_divergence=4.173016\n",
      "17:19:45 [INFO]: Epoch[7] Batch [160]\tSpeed: 1348.76 samples/sec\telbo=175.037628\tkl_divergence=4.240333\n",
      "17:19:47 [INFO]: Epoch[7] Batch [180]\tSpeed: 1526.78 samples/sec\telbo=175.410283\tkl_divergence=4.220719\n",
      "17:19:50 [INFO]: Epoch[7] Batch [200]\tSpeed: 1635.38 samples/sec\telbo=175.947118\tkl_divergence=4.320065\n",
      "17:19:52 [INFO]: Epoch[7] Batch [220]\tSpeed: 1526.34 samples/sec\telbo=173.678756\tkl_divergence=4.303049\n",
      "17:19:55 [INFO]: Epoch[7] Batch [240]\tSpeed: 1468.85 samples/sec\telbo=175.116197\tkl_divergence=4.231620\n",
      "17:19:57 [INFO]: Epoch[7] Train-elbo=173.753479\n",
      "17:19:57 [INFO]: Epoch[7] Train-kl_divergence=4.521286\n",
      "17:19:57 [INFO]: Epoch[7] Time cost=34.592\n",
      "17:19:57 [INFO]: Saved checkpoint to \"vae-0008.params\"\n",
      "17:19:59 [INFO]: Epoch[8] Batch [20]\tSpeed: 1583.64 samples/sec\telbo=172.787119\tkl_divergence=4.270681\n",
      "17:20:02 [INFO]: Epoch[8] Batch [40]\tSpeed: 1582.42 samples/sec\telbo=172.987248\tkl_divergence=4.407791\n",
      "17:20:05 [INFO]: Epoch[8] Batch [60]\tSpeed: 1407.08 samples/sec\telbo=174.292080\tkl_divergence=4.331631\n",
      "17:20:07 [INFO]: Epoch[8] Batch [80]\tSpeed: 1551.17 samples/sec\telbo=174.538534\tkl_divergence=4.398429\n",
      "17:20:10 [INFO]: Epoch[8] Batch [100]\tSpeed: 1596.98 samples/sec\telbo=173.716594\tkl_divergence=4.525004\n",
      "17:20:12 [INFO]: Epoch[8] Batch [120]\tSpeed: 1623.06 samples/sec\telbo=173.090368\tkl_divergence=4.357669\n",
      "17:20:15 [INFO]: Epoch[8] Batch [140]\tSpeed: 1556.15 samples/sec\telbo=173.388215\tkl_divergence=4.409557\n",
      "17:20:17 [INFO]: Epoch[8] Batch [160]\tSpeed: 1599.57 samples/sec\telbo=172.993744\tkl_divergence=4.464192\n",
      "17:20:20 [INFO]: Epoch[8] Batch [180]\tSpeed: 1459.67 samples/sec\telbo=173.215132\tkl_divergence=4.497549\n",
      "17:20:22 [INFO]: Epoch[8] Batch [200]\tSpeed: 1582.70 samples/sec\telbo=174.036605\tkl_divergence=4.490746\n",
      "17:20:25 [INFO]: Epoch[8] Batch [220]\tSpeed: 1633.37 samples/sec\telbo=171.579634\tkl_divergence=4.540319\n",
      "17:20:28 [INFO]: Epoch[8] Batch [240]\tSpeed: 1546.24 samples/sec\telbo=172.946817\tkl_divergence=4.518778\n",
      "17:20:29 [INFO]: Epoch[8] Train-elbo=171.729488\n",
      "17:20:29 [INFO]: Epoch[8] Train-kl_divergence=4.751735\n",
      "17:20:29 [INFO]: Epoch[8] Time cost=32.264\n",
      "17:20:29 [INFO]: Saved checkpoint to \"vae-0009.params\"\n",
      "17:20:32 [INFO]: Epoch[9] Batch [20]\tSpeed: 1560.81 samples/sec\telbo=170.441170\tkl_divergence=4.554904\n",
      "17:20:34 [INFO]: Epoch[9] Batch [40]\tSpeed: 1627.93 samples/sec\telbo=170.626806\tkl_divergence=4.591038\n",
      "17:20:37 [INFO]: Epoch[9] Batch [60]\tSpeed: 1619.93 samples/sec\telbo=172.008052\tkl_divergence=4.594543\n",
      "17:20:39 [INFO]: Epoch[9] Batch [80]\tSpeed: 1368.53 samples/sec\telbo=172.284275\tkl_divergence=4.600114\n",
      "17:20:42 [INFO]: Epoch[9] Batch [100]\tSpeed: 1344.81 samples/sec\telbo=171.231872\tkl_divergence=4.764554\n",
      "17:20:46 [INFO]: Epoch[9] Batch [120]\tSpeed: 1175.36 samples/sec\telbo=170.217947\tkl_divergence=4.726924\n",
      "17:20:49 [INFO]: Epoch[9] Batch [140]\tSpeed: 1188.99 samples/sec\telbo=170.542594\tkl_divergence=4.817586\n",
      "17:20:53 [INFO]: Epoch[9] Batch [160]\tSpeed: 1116.33 samples/sec\telbo=170.089936\tkl_divergence=4.789132\n",
      "17:20:56 [INFO]: Epoch[9] Batch [180]\tSpeed: 1172.95 samples/sec\telbo=170.159656\tkl_divergence=4.839289\n",
      "17:21:00 [INFO]: Epoch[9] Batch [200]\tSpeed: 1192.17 samples/sec\telbo=170.658089\tkl_divergence=4.920962\n",
      "17:21:03 [INFO]: Epoch[9] Batch [220]\tSpeed: 1162.87 samples/sec\telbo=168.292796\tkl_divergence=4.874105\n",
      "17:21:06 [INFO]: Epoch[9] Batch [240]\tSpeed: 1248.31 samples/sec\telbo=169.269744\tkl_divergence=4.898393\n",
      "17:21:07 [INFO]: Epoch[9] Train-elbo=168.401923\n",
      "17:21:07 [INFO]: Epoch[9] Train-kl_divergence=4.900276\n",
      "17:21:07 [INFO]: Epoch[9] Time cost=38.603\n",
      "17:21:08 [INFO]: Saved checkpoint to \"vae-0010.params\"\n",
      "17:21:10 [INFO]: Epoch[10] Batch [20]\tSpeed: 1616.77 samples/sec\telbo=166.700227\tkl_divergence=4.930591\n",
      "17:21:13 [INFO]: Epoch[10] Batch [40]\tSpeed: 1421.54 samples/sec\telbo=166.625281\tkl_divergence=5.019164\n",
      "17:21:16 [INFO]: Epoch[10] Batch [60]\tSpeed: 1173.61 samples/sec\telbo=167.747694\tkl_divergence=4.802719\n",
      "17:21:19 [INFO]: Epoch[10] Batch [80]\tSpeed: 1314.06 samples/sec\telbo=167.873142\tkl_divergence=4.852984\n",
      "17:21:22 [INFO]: Epoch[10] Batch [100]\tSpeed: 1370.62 samples/sec\telbo=166.576268\tkl_divergence=4.865937\n",
      "17:21:25 [INFO]: Epoch[10] Batch [120]\tSpeed: 1326.07 samples/sec\telbo=165.223548\tkl_divergence=4.688022\n",
      "17:21:29 [INFO]: Epoch[10] Batch [140]\tSpeed: 1241.46 samples/sec\telbo=165.422255\tkl_divergence=4.601581\n",
      "17:21:32 [INFO]: Epoch[10] Batch [160]\tSpeed: 1192.91 samples/sec\telbo=164.739770\tkl_divergence=4.612527\n",
      "17:21:35 [INFO]: Epoch[10] Batch [180]\tSpeed: 1221.27 samples/sec\telbo=164.836476\tkl_divergence=4.592939\n",
      "17:21:38 [INFO]: Epoch[10] Batch [200]\tSpeed: 1256.13 samples/sec\telbo=165.090028\tkl_divergence=4.584612\n",
      "17:21:42 [INFO]: Epoch[10] Batch [220]\tSpeed: 1250.87 samples/sec\telbo=162.574979\tkl_divergence=4.613817\n",
      "17:21:44 [INFO]: Epoch[10] Batch [240]\tSpeed: 1518.11 samples/sec\telbo=163.189082\tkl_divergence=4.741908\n",
      "17:21:45 [INFO]: Epoch[10] Train-elbo=161.902178\n",
      "17:21:45 [INFO]: Epoch[10] Train-kl_divergence=4.886702\n",
      "17:21:45 [INFO]: Epoch[10] Time cost=37.952\n",
      "17:21:46 [INFO]: Saved checkpoint to \"vae-0011.params\"\n",
      "17:21:48 [INFO]: Epoch[11] Batch [20]\tSpeed: 1598.25 samples/sec\telbo=160.369127\tkl_divergence=4.885464\n",
      "17:21:51 [INFO]: Epoch[11] Batch [40]\tSpeed: 1606.85 samples/sec\telbo=159.457132\tkl_divergence=5.084068\n",
      "17:21:53 [INFO]: Epoch[11] Batch [60]\tSpeed: 1618.90 samples/sec\telbo=159.942352\tkl_divergence=5.274405\n",
      "17:21:56 [INFO]: Epoch[11] Batch [80]\tSpeed: 1616.04 samples/sec\telbo=159.719956\tkl_divergence=5.464371\n",
      "17:21:58 [INFO]: Epoch[11] Batch [100]\tSpeed: 1631.46 samples/sec\telbo=158.177116\tkl_divergence=5.607343\n",
      "17:22:01 [INFO]: Epoch[11] Batch [120]\tSpeed: 1630.40 samples/sec\telbo=156.346432\tkl_divergence=5.798034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:22:03 [INFO]: Epoch[11] Batch [140]\tSpeed: 1629.33 samples/sec\telbo=156.038940\tkl_divergence=5.891057\n",
      "17:22:06 [INFO]: Epoch[11] Batch [160]\tSpeed: 1549.64 samples/sec\telbo=155.826377\tkl_divergence=5.888001\n",
      "17:22:08 [INFO]: Epoch[11] Batch [180]\tSpeed: 1434.74 samples/sec\telbo=155.885278\tkl_divergence=5.909804\n",
      "17:22:11 [INFO]: Epoch[11] Batch [200]\tSpeed: 1626.33 samples/sec\telbo=155.896653\tkl_divergence=6.042353\n",
      "17:22:13 [INFO]: Epoch[11] Batch [220]\tSpeed: 1624.41 samples/sec\telbo=153.221957\tkl_divergence=6.070427\n",
      "17:22:16 [INFO]: Epoch[11] Batch [240]\tSpeed: 1625.37 samples/sec\telbo=153.997139\tkl_divergence=6.164116\n",
      "17:22:17 [INFO]: Epoch[11] Train-elbo=153.035526\n",
      "17:22:17 [INFO]: Epoch[11] Train-kl_divergence=6.195086\n",
      "17:22:17 [INFO]: Epoch[11] Time cost=31.557\n",
      "17:22:17 [INFO]: Saved checkpoint to \"vae-0012.params\"\n",
      "17:22:20 [INFO]: Epoch[12] Batch [20]\tSpeed: 1480.35 samples/sec\telbo=152.016772\tkl_divergence=6.191890\n",
      "17:22:23 [INFO]: Epoch[12] Batch [40]\tSpeed: 1437.96 samples/sec\telbo=151.865820\tkl_divergence=6.123278\n",
      "17:22:26 [INFO]: Epoch[12] Batch [60]\tSpeed: 1445.96 samples/sec\telbo=152.761858\tkl_divergence=6.214226\n",
      "17:22:28 [INFO]: Epoch[12] Batch [80]\tSpeed: 1490.97 samples/sec\telbo=153.184451\tkl_divergence=6.222329\n",
      "17:22:31 [INFO]: Epoch[12] Batch [100]\tSpeed: 1608.78 samples/sec\telbo=151.866476\tkl_divergence=6.249096\n",
      "17:22:33 [INFO]: Epoch[12] Batch [120]\tSpeed: 1517.84 samples/sec\telbo=150.800159\tkl_divergence=6.261659\n",
      "17:22:36 [INFO]: Epoch[12] Batch [140]\tSpeed: 1545.71 samples/sec\telbo=150.420006\tkl_divergence=6.415310\n",
      "17:22:39 [INFO]: Epoch[12] Batch [160]\tSpeed: 1507.39 samples/sec\telbo=150.370741\tkl_divergence=6.292518\n",
      "17:22:41 [INFO]: Epoch[12] Batch [180]\tSpeed: 1459.73 samples/sec\telbo=150.532149\tkl_divergence=6.404047\n",
      "17:22:44 [INFO]: Epoch[12] Batch [200]\tSpeed: 1526.47 samples/sec\telbo=151.006222\tkl_divergence=6.405071\n",
      "17:22:47 [INFO]: Epoch[12] Batch [220]\tSpeed: 1565.34 samples/sec\telbo=148.466152\tkl_divergence=6.422328\n",
      "17:22:49 [INFO]: Epoch[12] Batch [240]\tSpeed: 1597.41 samples/sec\telbo=149.034669\tkl_divergence=6.534350\n",
      "17:22:50 [INFO]: Epoch[12] Train-elbo=147.777472\n",
      "17:22:50 [INFO]: Epoch[12] Train-kl_divergence=6.543469\n",
      "17:22:50 [INFO]: Epoch[12] Time cost=33.086\n",
      "17:22:50 [INFO]: Saved checkpoint to \"vae-0013.params\"\n",
      "17:22:53 [INFO]: Epoch[13] Batch [20]\tSpeed: 1471.39 samples/sec\telbo=146.760514\tkl_divergence=6.575677\n",
      "17:22:56 [INFO]: Epoch[13] Batch [40]\tSpeed: 1598.23 samples/sec\telbo=147.126339\tkl_divergence=6.538258\n",
      "17:22:58 [INFO]: Epoch[13] Batch [60]\tSpeed: 1487.98 samples/sec\telbo=148.210101\tkl_divergence=6.521149\n",
      "17:23:01 [INFO]: Epoch[13] Batch [80]\tSpeed: 1550.52 samples/sec\telbo=148.364732\tkl_divergence=6.639551\n",
      "17:23:04 [INFO]: Epoch[13] Batch [100]\tSpeed: 1435.59 samples/sec\telbo=146.855839\tkl_divergence=6.738368\n",
      "17:23:06 [INFO]: Epoch[13] Batch [120]\tSpeed: 1543.12 samples/sec\telbo=145.986564\tkl_divergence=6.681764\n",
      "17:23:09 [INFO]: Epoch[13] Batch [140]\tSpeed: 1556.62 samples/sec\telbo=145.484420\tkl_divergence=6.798220\n",
      "17:23:12 [INFO]: Epoch[13] Batch [160]\tSpeed: 1537.07 samples/sec\telbo=145.520139\tkl_divergence=6.754315\n",
      "17:23:14 [INFO]: Epoch[13] Batch [180]\tSpeed: 1517.83 samples/sec\telbo=145.600637\tkl_divergence=6.751496\n",
      "17:23:17 [INFO]: Epoch[13] Batch [200]\tSpeed: 1520.66 samples/sec\telbo=146.196501\tkl_divergence=6.796878\n",
      "17:23:19 [INFO]: Epoch[13] Batch [220]\tSpeed: 1544.71 samples/sec\telbo=144.223325\tkl_divergence=6.759509\n",
      "17:23:22 [INFO]: Epoch[13] Batch [240]\tSpeed: 1462.31 samples/sec\telbo=144.307570\tkl_divergence=6.997125\n",
      "17:23:23 [INFO]: Epoch[13] Train-elbo=142.735076\n",
      "17:23:23 [INFO]: Epoch[13] Train-kl_divergence=6.930786\n",
      "17:23:23 [INFO]: Epoch[13] Time cost=33.011\n",
      "17:23:23 [INFO]: Saved checkpoint to \"vae-0014.params\"\n",
      "17:23:26 [INFO]: Epoch[14] Batch [20]\tSpeed: 1558.85 samples/sec\telbo=142.277759\tkl_divergence=6.947636\n",
      "17:23:29 [INFO]: Epoch[14] Batch [40]\tSpeed: 1553.43 samples/sec\telbo=142.946151\tkl_divergence=6.931661\n",
      "17:23:31 [INFO]: Epoch[14] Batch [60]\tSpeed: 1565.30 samples/sec\telbo=143.923632\tkl_divergence=6.914600\n",
      "17:23:34 [INFO]: Epoch[14] Batch [80]\tSpeed: 1618.62 samples/sec\telbo=144.090010\tkl_divergence=6.933619\n",
      "17:23:36 [INFO]: Epoch[14] Batch [100]\tSpeed: 1528.32 samples/sec\telbo=142.790621\tkl_divergence=7.055412\n",
      "17:23:39 [INFO]: Epoch[14] Batch [120]\tSpeed: 1527.32 samples/sec\telbo=141.766330\tkl_divergence=7.061503\n",
      "17:23:41 [INFO]: Epoch[14] Batch [140]\tSpeed: 1542.83 samples/sec\telbo=141.428301\tkl_divergence=7.046105\n",
      "17:23:44 [INFO]: Epoch[14] Batch [160]\tSpeed: 1523.66 samples/sec\telbo=141.297477\tkl_divergence=7.147517\n",
      "17:23:47 [INFO]: Epoch[14] Batch [180]\tSpeed: 1476.88 samples/sec\telbo=141.378350\tkl_divergence=7.185161\n",
      "17:23:50 [INFO]: Epoch[14] Batch [200]\tSpeed: 1448.03 samples/sec\telbo=141.572927\tkl_divergence=7.273219\n",
      "17:23:52 [INFO]: Epoch[14] Batch [220]\tSpeed: 1497.98 samples/sec\telbo=139.408813\tkl_divergence=7.216134\n",
      "17:23:55 [INFO]: Epoch[14] Batch [240]\tSpeed: 1446.49 samples/sec\telbo=138.705431\tkl_divergence=7.483765\n",
      "17:23:56 [INFO]: Epoch[14] Train-elbo=137.326722\n",
      "17:23:56 [INFO]: Epoch[14] Train-kl_divergence=7.531100\n",
      "17:23:56 [INFO]: Epoch[14] Time cost=32.942\n",
      "17:23:56 [INFO]: Saved checkpoint to \"vae-0015.params\"\n",
      "17:23:59 [INFO]: Epoch[15] Batch [20]\tSpeed: 1526.06 samples/sec\telbo=136.642264\tkl_divergence=7.485217\n",
      "17:24:02 [INFO]: Epoch[15] Batch [40]\tSpeed: 1561.95 samples/sec\telbo=136.689397\tkl_divergence=7.587383\n",
      "17:24:04 [INFO]: Epoch[15] Batch [60]\tSpeed: 1623.95 samples/sec\telbo=137.162381\tkl_divergence=7.711205\n",
      "17:24:07 [INFO]: Epoch[15] Batch [80]\tSpeed: 1626.89 samples/sec\telbo=137.225401\tkl_divergence=7.699719\n",
      "17:24:09 [INFO]: Epoch[15] Batch [100]\tSpeed: 1624.72 samples/sec\telbo=135.661903\tkl_divergence=7.742916\n",
      "17:24:12 [INFO]: Epoch[15] Batch [120]\tSpeed: 1629.92 samples/sec\telbo=134.333707\tkl_divergence=7.733340\n",
      "17:24:14 [INFO]: Epoch[15] Batch [140]\tSpeed: 1597.26 samples/sec\telbo=133.573699\tkl_divergence=7.847087\n",
      "17:24:17 [INFO]: Epoch[15] Batch [160]\tSpeed: 1555.70 samples/sec\telbo=133.649054\tkl_divergence=7.837318\n",
      "17:24:19 [INFO]: Epoch[15] Batch [180]\tSpeed: 1509.28 samples/sec\telbo=133.591507\tkl_divergence=7.899623\n",
      "17:24:22 [INFO]: Epoch[15] Batch [200]\tSpeed: 1463.24 samples/sec\telbo=133.682420\tkl_divergence=7.985373\n",
      "17:24:25 [INFO]: Epoch[15] Batch [220]\tSpeed: 1558.72 samples/sec\telbo=131.648419\tkl_divergence=7.840947\n",
      "17:24:27 [INFO]: Epoch[15] Batch [240]\tSpeed: 1435.19 samples/sec\telbo=131.621033\tkl_divergence=7.995602\n",
      "17:24:29 [INFO]: Epoch[15] Train-elbo=130.935967\n",
      "17:24:29 [INFO]: Epoch[15] Train-kl_divergence=7.830305\n",
      "17:24:29 [INFO]: Epoch[15] Time cost=32.213\n",
      "17:24:29 [INFO]: Saved checkpoint to \"vae-0016.params\"\n",
      "17:24:31 [INFO]: Epoch[16] Batch [20]\tSpeed: 1547.31 samples/sec\telbo=130.062986\tkl_divergence=7.940544\n",
      "17:24:34 [INFO]: Epoch[16] Batch [40]\tSpeed: 1440.22 samples/sec\telbo=130.355136\tkl_divergence=7.984832\n",
      "17:24:37 [INFO]: Epoch[16] Batch [60]\tSpeed: 1537.53 samples/sec\telbo=131.097604\tkl_divergence=8.084154\n",
      "17:24:39 [INFO]: Epoch[16] Batch [80]\tSpeed: 1506.78 samples/sec\telbo=131.717596\tkl_divergence=8.007076\n",
      "17:24:42 [INFO]: Epoch[16] Batch [100]\tSpeed: 1321.67 samples/sec\telbo=130.323577\tkl_divergence=8.144594\n",
      "17:24:45 [INFO]: Epoch[16] Batch [120]\tSpeed: 1519.89 samples/sec\telbo=129.069389\tkl_divergence=8.164850\n",
      "17:24:48 [INFO]: Epoch[16] Batch [140]\tSpeed: 1495.95 samples/sec\telbo=128.686703\tkl_divergence=8.143524\n",
      "17:24:50 [INFO]: Epoch[16] Batch [160]\tSpeed: 1500.92 samples/sec\telbo=129.263553\tkl_divergence=8.165692\n",
      "17:24:53 [INFO]: Epoch[16] Batch [180]\tSpeed: 1493.59 samples/sec\telbo=129.344085\tkl_divergence=8.166807\n",
      "17:24:56 [INFO]: Epoch[16] Batch [200]\tSpeed: 1370.60 samples/sec\telbo=129.573347\tkl_divergence=8.235156\n",
      "17:24:59 [INFO]: Epoch[16] Batch [220]\tSpeed: 1396.15 samples/sec\telbo=127.788330\tkl_divergence=8.203454\n",
      "17:25:02 [INFO]: Epoch[16] Batch [240]\tSpeed: 1461.45 samples/sec\telbo=127.938873\tkl_divergence=8.277423\n",
      "17:25:03 [INFO]: Epoch[16] Train-elbo=127.122042\n",
      "17:25:03 [INFO]: Epoch[16] Train-kl_divergence=8.193737\n",
      "17:25:03 [INFO]: Epoch[16] Time cost=34.161\n",
      "17:25:03 [INFO]: Saved checkpoint to \"vae-0017.params\"\n",
      "17:25:05 [INFO]: Epoch[17] Batch [20]\tSpeed: 1584.92 samples/sec\telbo=126.607772\tkl_divergence=8.219927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:25:08 [INFO]: Epoch[17] Batch [40]\tSpeed: 1583.50 samples/sec\telbo=127.032885\tkl_divergence=8.256328\n",
      "17:25:11 [INFO]: Epoch[17] Batch [60]\tSpeed: 1455.07 samples/sec\telbo=128.093535\tkl_divergence=8.283130\n",
      "17:25:13 [INFO]: Epoch[17] Batch [80]\tSpeed: 1578.46 samples/sec\telbo=128.789406\tkl_divergence=8.216385\n",
      "17:25:16 [INFO]: Epoch[17] Batch [100]\tSpeed: 1516.22 samples/sec\telbo=127.210673\tkl_divergence=8.370418\n",
      "17:25:19 [INFO]: Epoch[17] Batch [120]\tSpeed: 1459.24 samples/sec\telbo=126.485008\tkl_divergence=8.199404\n",
      "17:25:21 [INFO]: Epoch[17] Batch [140]\tSpeed: 1595.09 samples/sec\telbo=126.106062\tkl_divergence=8.289238\n",
      "17:25:24 [INFO]: Epoch[17] Batch [160]\tSpeed: 1483.03 samples/sec\telbo=126.612697\tkl_divergence=8.336635\n",
      "17:25:26 [INFO]: Epoch[17] Batch [180]\tSpeed: 1590.79 samples/sec\telbo=126.582627\tkl_divergence=8.386572\n",
      "17:25:29 [INFO]: Epoch[17] Batch [200]\tSpeed: 1544.22 samples/sec\telbo=127.115250\tkl_divergence=8.373560\n",
      "17:25:32 [INFO]: Epoch[17] Batch [220]\tSpeed: 1513.98 samples/sec\telbo=125.271846\tkl_divergence=8.367921\n",
      "17:25:34 [INFO]: Epoch[17] Batch [240]\tSpeed: 1547.57 samples/sec\telbo=125.647164\tkl_divergence=8.382752\n",
      "17:25:35 [INFO]: Epoch[17] Train-elbo=124.767790\n",
      "17:25:35 [INFO]: Epoch[17] Train-kl_divergence=8.503218\n",
      "17:25:35 [INFO]: Epoch[17] Time cost=32.562\n",
      "17:25:35 [INFO]: Saved checkpoint to \"vae-0018.params\"\n",
      "17:25:38 [INFO]: Epoch[18] Batch [20]\tSpeed: 1541.46 samples/sec\telbo=124.272743\tkl_divergence=8.428614\n",
      "17:25:41 [INFO]: Epoch[18] Batch [40]\tSpeed: 1599.16 samples/sec\telbo=124.730185\tkl_divergence=8.449555\n",
      "17:25:43 [INFO]: Epoch[18] Batch [60]\tSpeed: 1473.61 samples/sec\telbo=125.640760\tkl_divergence=8.522361\n",
      "17:25:46 [INFO]: Epoch[18] Batch [80]\tSpeed: 1621.04 samples/sec\telbo=126.819680\tkl_divergence=8.304449\n",
      "17:25:48 [INFO]: Epoch[18] Batch [100]\tSpeed: 1608.15 samples/sec\telbo=125.173685\tkl_divergence=8.520082\n",
      "17:25:51 [INFO]: Epoch[18] Batch [120]\tSpeed: 1590.53 samples/sec\telbo=124.058009\tkl_divergence=8.426665\n",
      "17:25:53 [INFO]: Epoch[18] Batch [140]\tSpeed: 1523.62 samples/sec\telbo=123.849033\tkl_divergence=8.454551\n",
      "17:25:56 [INFO]: Epoch[18] Batch [160]\tSpeed: 1575.39 samples/sec\telbo=124.297408\tkl_divergence=8.556890\n",
      "17:25:59 [INFO]: Epoch[18] Batch [180]\tSpeed: 1557.03 samples/sec\telbo=124.441979\tkl_divergence=8.592064\n",
      "17:26:01 [INFO]: Epoch[18] Batch [200]\tSpeed: 1556.59 samples/sec\telbo=124.773761\tkl_divergence=8.654052\n",
      "17:26:04 [INFO]: Epoch[18] Batch [220]\tSpeed: 1402.64 samples/sec\telbo=123.080222\tkl_divergence=8.550377\n",
      "17:26:07 [INFO]: Epoch[18] Batch [240]\tSpeed: 1337.15 samples/sec\telbo=123.418719\tkl_divergence=8.572117\n",
      "17:26:08 [INFO]: Epoch[18] Train-elbo=122.320652\n",
      "17:26:08 [INFO]: Epoch[18] Train-kl_divergence=8.707286\n",
      "17:26:08 [INFO]: Epoch[18] Time cost=32.719\n",
      "17:26:08 [INFO]: Saved checkpoint to \"vae-0019.params\"\n",
      "17:26:11 [INFO]: Epoch[19] Batch [20]\tSpeed: 1562.35 samples/sec\telbo=122.006095\tkl_divergence=8.593190\n",
      "17:26:13 [INFO]: Epoch[19] Batch [40]\tSpeed: 1617.17 samples/sec\telbo=122.380562\tkl_divergence=8.633417\n",
      "17:26:16 [INFO]: Epoch[19] Batch [60]\tSpeed: 1632.16 samples/sec\telbo=123.419306\tkl_divergence=8.607139\n",
      "17:26:18 [INFO]: Epoch[19] Batch [80]\tSpeed: 1625.34 samples/sec\telbo=124.297629\tkl_divergence=8.468619\n",
      "17:26:21 [INFO]: Epoch[19] Batch [100]\tSpeed: 1611.56 samples/sec\telbo=122.823253\tkl_divergence=8.647570\n",
      "17:26:23 [INFO]: Epoch[19] Batch [120]\tSpeed: 1490.44 samples/sec\telbo=121.580905\tkl_divergence=8.700638\n",
      "17:26:26 [INFO]: Epoch[19] Batch [140]\tSpeed: 1458.74 samples/sec\telbo=121.379471\tkl_divergence=8.541854\n",
      "17:26:29 [INFO]: Epoch[19] Batch [160]\tSpeed: 1324.95 samples/sec\telbo=121.908088\tkl_divergence=8.593273\n",
      "17:26:32 [INFO]: Epoch[19] Batch [180]\tSpeed: 1600.01 samples/sec\telbo=122.007660\tkl_divergence=8.565349\n",
      "17:26:34 [INFO]: Epoch[19] Batch [200]\tSpeed: 1620.37 samples/sec\telbo=122.172159\tkl_divergence=8.733784\n",
      "17:26:37 [INFO]: Epoch[19] Batch [220]\tSpeed: 1605.68 samples/sec\telbo=120.681979\tkl_divergence=8.546265\n",
      "17:26:39 [INFO]: Epoch[19] Batch [240]\tSpeed: 1537.31 samples/sec\telbo=120.970559\tkl_divergence=8.595216\n",
      "17:26:40 [INFO]: Epoch[19] Train-elbo=120.281017\n",
      "17:26:40 [INFO]: Epoch[19] Train-kl_divergence=8.636666\n",
      "17:26:40 [INFO]: Epoch[19] Time cost=32.279\n",
      "17:26:40 [INFO]: Saved checkpoint to \"vae-0020.params\"\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "optimiser = \"adam\"\n",
    "\n",
    "vae_module.fit(train_data=train_iter, optimizer=optimiser, force_init=True, force_rebind=True, num_epoch=epochs,\n",
    "               optimizer_params={'learning_rate': DEFAULT_LEARNING_RATE},\n",
    "               batch_end_callback=mx.callback.Speedometer(frequent=20, batch_size=batch_size),\n",
    "               epoch_end_callback=mx.callback.do_checkpoint('vae'),\n",
    "               eval_metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VAE has converged nicely (arguably we could have trained it even longer). Observe how the KL divergence has increased towards the end of training. This means that the variational approximation has become increasingly specialised and distinct from the standard normal prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Data from the VAE\n",
    "\n",
    "Now that we have trained the VAE, we can use it to produce data for us. We first need to load the parameters and supply them to a new symbol that does the phantasizing. We then produce 10 random digits. The pixel intensities are the predicted Bernoulli parameters. **NOTE**: The width and height variables were computed in the beginning when we were first looking at our data set. We are simply reusing them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:28:00 [DEBUG]: update_title_pos\n",
      "17:28:00 [DEBUG]: update_title_pos\n",
      "17:28:00 [DEBUG]: update_title_pos\n",
      "17:28:00 [DEBUG]: update_title_pos\n",
      "17:28:00 [DEBUG]: update_title_pos\n",
      "17:28:00 [DEBUG]: update_title_pos\n",
      "17:28:00 [DEBUG]: update_title_pos\n",
      "17:28:00 [DEBUG]: update_title_pos\n",
      "17:28:01 [DEBUG]: update_title_pos\n",
      "17:28:01 [DEBUG]: update_title_pos\n",
      "17:28:01 [DEBUG]: update_title_pos\n",
      "17:28:01 [DEBUG]: update_title_pos\n",
      "17:28:01 [DEBUG]: update_title_pos\n",
      "17:28:01 [DEBUG]: update_title_pos\n",
      "17:28:01 [DEBUG]: update_title_pos\n",
      "17:28:01 [DEBUG]: update_title_pos\n",
      "17:28:01 [DEBUG]: update_title_pos\n",
      "17:28:01 [DEBUG]: update_title_pos\n",
      "17:28:01 [DEBUG]: update_title_pos\n",
      "17:28:01 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:02 [DEBUG]: update_title_pos\n",
      "17:28:03 [DEBUG]: update_title_pos\n",
      "17:28:03 [DEBUG]: update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x432 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = 10\n",
    "\n",
    "params = vae_module.get_params()[0]\n",
    "# We group the outputs of phantasize to be able to process them as a single symbol\n",
    "dream_digits = mx.sym.Group(vae.phantasize(num_samples))\n",
    "# construct an executor by binding the parameters to the learned values\n",
    "dream_exec = dream_digits.bind(ctx=ctx, args=params)\n",
    "\n",
    "# run the computation\n",
    "digits, latent_values = dream_exec.forward()\n",
    "\n",
    "# transform output into numpy arrays\n",
    "digits = digits.asnumpy()\n",
    "latent_values = latent_values.asnumpy()\n",
    "rows = int(num_samples / 5)\n",
    "\n",
    "plot, axes = plt.subplots(rows, 5,  sharex='col', sharey='row', figsize=(30,6))\n",
    "sample=0\n",
    "for row in range(rows):\n",
    "    for col in range(5):\n",
    "        axes[row][col].imshow(np.reshape(digits[sample,:],(width,height)), cmap=cm.Greys)\n",
    "        sample += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the above samples were obtained by sampling from the standard normal prior. We can also check the reconstruction abilities of the VAE. To do this we sample a random number from the test set and generate 10 reconstructions of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:08:23 [INFO]: Reading ./binary_mnist/binary_mnist.test into memory\n"
     ]
    }
   ],
   "source": [
    "file_name = join(data_dir, \"binary_mnist.{}\".format(TEST_SET))\n",
    "logging.info(\"Reading {} into memory\".format(file_name))\n",
    "test_set = np.genfromtxt(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the sampled number looks like. (Rerun if you want a different number.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:28:41 [DEBUG]: update_title_pos\n",
      "17:28:41 [DEBUG]: update_title_pos\n",
      "17:28:41 [DEBUG]: update_title_pos\n",
      "17:28:41 [DEBUG]: update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_idx = np.random.randint(test_set.shape[0])\n",
    "random_picture = test_set[random_idx, :]\n",
    "plot, canvas = plt.subplots(1, figsize=(5,5))\n",
    "canvas.imshow(np.reshape(random_picture,(width,height)), cmap=cm.Greys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are going to see how the VAE reconstructs it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:28:49 [DEBUG]: update_title_pos\n",
      "17:28:49 [DEBUG]: update_title_pos\n",
      "17:28:49 [DEBUG]: update_title_pos\n",
      "17:28:49 [DEBUG]: update_title_pos\n",
      "17:28:49 [DEBUG]: update_title_pos\n",
      "17:28:49 [DEBUG]: update_title_pos\n",
      "17:28:49 [DEBUG]: update_title_pos\n",
      "17:28:49 [DEBUG]: update_title_pos\n",
      "17:28:49 [DEBUG]: update_title_pos\n",
      "17:28:49 [DEBUG]: update_title_pos\n",
      "17:28:50 [DEBUG]: update_title_pos\n",
      "17:28:50 [DEBUG]: update_title_pos\n",
      "17:28:50 [DEBUG]: update_title_pos\n",
      "17:28:50 [DEBUG]: update_title_pos\n",
      "17:28:50 [DEBUG]: update_title_pos\n",
      "17:28:50 [DEBUG]: update_title_pos\n",
      "17:28:50 [DEBUG]: update_title_pos\n",
      "17:28:50 [DEBUG]: update_title_pos\n",
      "17:28:50 [DEBUG]: update_title_pos\n",
      "17:28:50 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n",
      "17:28:51 [DEBUG]: update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABiMAAAFpCAYAAAD+2FukAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3WmMned1H/DzcN/X4SYu4iKJonZZlGRbSxS7VqqkRZK2aeOiRoK0UBrERQu0QI1+SdFP+dAFKAIUdWDHNpqmLlDHFmKlsiprsSBbMmVtXLRSpLiK+87h+vaD2Ubhc17xDmdecmb0+wGGyL/ec+97R55zn/s8HJ7SNE0AAAAAAAB0ZczVvgEAAAAAAGB0cxgBAAAAAAB0ymEEAAAAAADQKYcRAAAAAABApxxGAAAAAAAAnXIYAQAAAAAAdMphBAAAAAAA0CmHEQAAAAAAQKcGdRhRSvmbpZS3SinvllK+MlQ3BQAAAAAAjB6laZrLKyxlbES8HRFfiIjtEfHTiPhi0zQbh+72AAAAAACAkW7cIGrviYh3m6bZHBFRSvkfEfGrEdF6GNHX19csX758EE8Jf2XLli2xb9++crXvA4YTfZah9vLLL+9rmmbe1b4PGE70WoaSNS3U9FmGkj4LNX2Wodbr3sFgDiMWR8S2j/x+e0Tc+3EFy5cvj3Xr1g3iKeGvrF279mrfAgw7+ixDrZSy9WrfAww3ei1DyZoWavosQ0mfhZo+y1Drde+g8wHWpZRHSynrSinr9u7d2/XTAXzi6LMA3dNrAbqlzwJ0S59lOBjMYcSOiFj6kd8vuZD9NU3TfLVpmrVN06ydN8/f8gAw1PRZgO7ptQDd0mcBuqXPMhwM5jDipxFxfSllRSllQkT8ZkQ8NjS3BQAAAAAAjBaXPTOiaZqzpZQvR8QTETE2Ir7eNM2GIbszAAAAAABgVBjMAOtomubxiHh8iO4FAAAAAAAYhTofYA0AAAAAAHyyOYwAAAAAAAA65TACAAAAAADolMMIAAAAAACgUw4jAAAAAACATjmMAAAAAAAAOuUwAgAAAAAA6JTDCAAAAAAAoFMOIwAAAAAAgE45jAAAAAAAADrlMAIAAAAAAOiUwwgAAAAAAKBTDiMAAAAAAIBOjbvaN3C1NU3TSf25c+d6yvr7+3vKBmLy5MlpPnbs2CobN67+v0B2XVteSun5vgZyLfDJNJCenPXUM2fOVNnBgwer7MCBA+ljnjhxoqd76uvrS+unTp1aZVOmTKmyiRMnpvVZTx4zpvc/N6DPAr3ootceO3asyo4fP97zY2amTZuW5pMmTaqy8ePH95RF9L6m1VOBXgx2TyHriWfPnq2ybJ8gW7tGRJw/f76nLFu7RuRr0iwbSJ+1pgUupas92qz/Zb339OnTPV03EFnvjMh7YpaNxj1aPxkBAAAAAAB0ymEEAAAAAADQKYcRAAAAAABApxxGAAAAAAAAnRrUAOtSypaIOBoR5yLibNM0a4fipgAAAAAAgNFjUIcRF/xi0zT7huBxOpdNVW+btJ7lZ8+erbITJ06k9W+//XaVvfDCC1X25ptvVtmBAwfSxzx+/HiVTZgwocoWLFiQ1q9evbrKli1bVmV33313Wj937tyenr9tUnzmak5vB66Mtj6bOX/+fJWdOnUqvXbHjh1V9uyzz1bZj3/84yp7991308c8evTopW4xIiKuueaaNM/67IoVK6rs4YcfTusXLVpUZRMnTqwyfRY+2QbSV7Nrz507V2X9/f1p/ebNm6ss67Wvv/56lWV9OiJfP48ZU//A9uLFi9P6G2+8scpWrlxZZffdd19a39fXV2XZmnbs2LFpfdZX9VoYXQbbZweypt25c2eVvfTSS1X2yiuvVNlA+mwm+4wfkffUbP37wAMPpPXZnkS2ph0/fvylbvH/02dh5Oq1pw5kj3Yg69lt27ZV2bp166os26Pdv39/+phZT88+py9cuDCtz/YJsmtvv/32tH727NlVNlL2aP01TQAAAAAAQKcGexjRRMQPSikvl1IeHYobAgAAAAAARpfBHkbc3zTNpyLikYj4/VLKgxdfUEp5tJSyrpSybu/evYN8OgAups8CdE+vBeiWPgvQLX2W4WBQhxFN0+y48M89EfHnEXFPcs1Xm6ZZ2zTN2nnz5g3m6QBI6LMA3dNrAbqlzwJ0S59lOLjsAdallKkRMaZpmqMXfv1wRPy7IbuzQep1WHU28CQi4vTp01X2/vvvV9kPfvCDtP4v//Ivq+ydd96psmwodTYou012/1OmTEmvnTlzZpWtXbu2ys6cOZPWf+Yzn6myrHllAwgj2ocAAqNHr703Iu9fx44dq7L169en9V//+ter7IUXXqiyffv2VVnW49tkAwi3bt2aXpsNFrz55purrO1r8sgjj1RZNtR6IENVgZGt14F/Wa+KyNeVe/bsqbJnnnkmrf/2t79dZRs2bKiyI0eOVFnbmrLXYa+TJ09O67Nef+edd1ZZ2xDDX/zFX6yybNhq25pWr4XRZbB9NlvTHjp0qMpef/31tP5P//RPq+zll1+usmyIattQ7MH22WnTplXZHXfc0dNjRkQ89NBDVTaQNa29AxiZeu2nbde29ZRsTblr164qe/7559P6v/iLv6iybD179OjRKmvrs5ns/mfMmJFe29fXV2W33nprlWX7xhER99xT/TxAzJ8/v8qG4x7tZR9GRMSCiPjzC4vxcRHx35um+d9DclcAAAAAAMCocdmHEU3TbI6I24fwXgAAAAAAgFFosAOsAQAAAAAAPpbDCAAAAAAAoFODmRkxLLQNR+l1WPXJkyfT+k2bNlXZ1772tSp76qmn0vpsiF82yGTSpElV1jZEKrs2G+LS9pqyIVqvvvpqlbUNV7nmmmt6uqcJEyak9cDo0utwqqz3RkQcPny4yh5//PEq+5M/+ZO0/s0336yybAD2+PHjq2zKlCnpY86aNavKsoFP2b1H5MNS33777Sr70Y9+lNZng/2y94RsMFVE+3AqYHTJ1pRtw6K3bdtWZX/8x39cZd/97nfT+mxgavZcWa9tW9NmPTh7TSdOnEjrsx78yiuvVFnbmjTr9WvXrq2yrCdH6LXwSZCtc8+ePZtem/XJxx57rMq+/e1vp/Xvv/9+lWWf6bM+O3Xq1PQxZ86cmeYXy/YtIvKBqdnae/bs2Wn98uXLqyzr/fPmzbvEHQKjQa/DqtuGRWd98r/9t/9WZU888URaf+DAgSrL1rPZ2rFtPdvWfy/Wtp7ds2dPlWV70W39PFunTpw4scqGY5+1kgYAAAAAADrlMAIAAAAAAOiUwwgAAAAAAKBTDiMAAAAAAIBOOYwAAAAAAAA6Ne5q38CVdPbs2Srbu3dveu33v//9Kvvxj39cZQcPHkzrswns2aTzNWvWVNmyZcvSx8ycPn26ynbt2pVeu3PnzirLpsdv27YtrX/nnXeqbMmSJVU2a9astH7s2LFVVkpJrwVGpvPnz1fZqVOn0ms3bNhQZd/5zneq7LXXXkvrs/43derUKrvuuuuq7I477kgfc/bs2VU2blz9Vrl9+/a0/oMPPqiyrCe///77af0bb7xRZTfccEOVzZkzJ63XZ+GT4dy5c1V26NCh9Nqsr/7FX/xFlWXrxIi8h8yYMaPKVq9e3VMWka+TM7t3707zHTt2VFm2Js/WrhERP/3pT6ts6dKlVTZ37ty0Xq+F0S/rs/39/em12Vr1//yf/1Nlb7/9ds/Pla31brrppirL1rkREdOmTauyMWPqP4va1mezPHuf+fDDD9P6rP9m+xzZ2jtCn4VPgmyP9sCBA+m1TzzxRJW98MILVdbWk8aPH19l2dpv1apVPV0Xka9nsz67b9++tH7//v1Vlr3PtO3xbt68ucoWLlxYZcOxz/rJCAAAAAAAoFMOIwAAAAAAgE45jAAAAAAAADrlMAIAAAAAAOjUiB9g3TZco9chqtmw0IiIn/3sZ1W2Z8+eKmsbwJcNHP3CF75QZbfeemuVLV68OH3M7LVmw03efPPNtH7Tpk1Vlg2QPXnyZM/1d999d5VlQ2gi8oExwOiSDeDLemdExGOPPVZlL730UpWdOXMmrZ8+fXqV/cIv/EKV3XfffVWW9a6IiClTplRZ9n6ydevWtP7ll1+usp/85CdVtnfv3rQ+67PZUNlsAGBE3mezIVrAyNE0TZVla9p169al9dnAv23btvX8/NkQ52xNe88991RZNmw1Iu9VWa/NBvNFRLz++utVlr1/tPXabP2frcnbeu3EiROrTK+F0SVb07YNEc36bLYmzPpcRMSiRYuq7POf/3yV3XnnnVWW7TtEREyePLmn58/WmRH5nkK2R3L48OG0PhvWfdddd1XZggUL0nprWhhdel3Pbty4Ma3PhlVn68S2Pdo1a9ZU2YMPPlhl119/fZUtWbIkfcxJkyal+cV2796d5u+//36VZWvctj6b7R1ka++2Ptv2tboSdHMAAAAAAKBTDiMAAAAAAIBOOYwAAAAAAAA6dcnDiFLK10spe0op6z+SzSmlPFlKeefCP2d3e5sAAAAAAMBI1csA629ExB9FxLc+kn0lIp5qmuYPSylfufD7fz30t3dp2RCUiHw404kTJ6qsbYB1Npw0GyA9f/78tP7ee++tsmyI6pw5c6ps5syZ6WNmQ5yOHj1aZbfccktanw2mPnDgQJW1DVfZsWNHlR08eLDK2v6bAKNL9r1++vTpKlu/fn2VReSDnbM+3TYYKhvi98gjj1RZ1hPbenf2XP39/T3fU/b6s8GAWe+OyPvsO++8U2XZAEBgdMrWtIcOHaqyp59+Oq3Phohmjzljxoy0Plu/Zr125cqVVTZ7dv7nlXrttW1r4mywbLZ+PXLkSFr/wQcfVFk2BPD+++9P6611YXTJemK2ptuwYUNanw0czQaztvXZtWvXVtkDDzxQZdkQ1b6+vvQxe+2z2aDriIixY8dWWdZTs3VqRMS+ffuqLFsTX3fddWl9tvcCjFxZnz127FiVvfjii2l9W6+52MKFC9M8+/yc9d5Zs2ZVWbZvG5H3z+y9Y+rUqWn9xIkTqyzbD8nW8hERe/furbLt27dX2YoVK9L6q7meveRPRjRN81xEXLxj/asR8c0Lv/5mRPzaEN8XAAAAAAAwSlzuzIgFTdPsuvDr3RGxYIjuBwAAAAAAGGUGPcC6+fnPdbT+bEcp5dFSyrpSyrrsR0gAGBx9FqB7ei1At/RZgG7pswwHl3sY8WEpZVFExIV/7mm7sGmarzZNs7ZpmrXz5s27zKcDoI0+C9A9vRagW/osQLf0WYaDyz2MeCwifuvCr38rIr43NLcDAAAAAACMNuMudUEp5c8i4qGI6CulbI+IP4iIP4yI/1lK+ccRsTUi/n6XN3k5zp07V2UHDlw8hztiy5YtaX021b2UUmV9fX1p/fXXX19lc+fOrbJsevq4cZf8z/Kx106ZMiW9dtWqVVWWvf62r8mpU6eq7N13362yu+++O60HRpeszx49erTKXnrppbR+586dVXb+/Pkqmz17dlr/wAMPVNk999xTZVOnTq2ytj45duzYKvv530Z46esiIlasWFFlS5YsqbL169en9R9++GGVvfXWW1WWfZ2AkS3rNRERZ86cqbIPPvigyjZs2JDWnzhxosrGjKn/PNLChQvT+vvuu6/Kbr755iqbPHlylbX12uz5M2299oYbbqiy7PW/9tpraf2hQ4eq7O23366ytl7b9t8KGN7avnezNe3hw4er7JVXXknrd+3aVWVZ/2jbO7jzzjurbOXKlVU2adKkKpswYUL6mFmfHT9+fJW17T1k69drr722yt555520/uDBg1WW9dkHH3wwrddnYWQayHp29+7dVZZ99o2IOHLkSE/P3/bTHqtXr66y+fPnV1nWJ7vqs4sWLaqyZcuWVVnWOyPy96msJ2f7JlfbJXe9m6b5Ysu/+vwQ3wsAAAAAADAKDXqANQAAAAAAwMdxGAEAAAAAAHTKYQQAAAAAANCp3iclD1Ntw1GygVHZwJNs2FRERH9/f5Vlw0myodQREdOnT6+ybOBUNsjk7Nmz6WNm+enTp6ssG8oXEbF///4qy4Z1nTx5sufnz4aCt91/NgAcGP4G0mez/tM2hOrYsWNVlg18WrNmTVqfDfvLhl1nj9k2PDV7TVnvygZwReTDVrMB2m39MOuf+/btq7JsIG1E+3sSMPwNZODfe++9V2XZUOu2+okTJ1ZZW6/N8pkzZ1ZZ1v8G0msz2To3Iv9aZb22bQB2tv7du3dvlbWtqRcvXpzmwMjU65p2IENEs/6TDYCOiFi6dGmVzZgxo8qyvYO2NWXW+7PeeerUqZ7rs56e9dOIfO9lz549Vda2ps3eZ4Dhr209m33O3bFjR5Vt3rw5rc/2KadMmVJl2VDqiIhZs2b1VN+2dsxk69SsJ2f7y2151nvb6rP3qWwo+PHjx9P6bO/kSvGTEQAAAAAAQKccRgAAAAAAAJ1yGAEAAAAAAHTKYQQAAAAAANCpET/Auk02HOXFF1+ssm3btqX12SCSBQsWVFlfX19av2jRokvdYkTkg1XbBkBnsuEw2VDCiHw4STZcpe35jx49WmVbtmzpuR4YXbLhSs8880yVrV+/Pq3PBuYtWbKkym6//fa0/vrrr6+yCRMmVFk27K9teGrbEMCLZcOu2mRDtLL7jMj754EDB6qsbVggMHK1Dfw7duxYlT333HNVlg1gbnvcbJ26evXqtD4brJr11WxN29ar2gZbX6yt186dO7fKsnX6pEmT0vrsPSD7+rUN/Gv7bwUMb23fu9ma9tlnn62yTZs2pfXZmjYbVr1y5cq0fsWKFVWW9dTsc/5A+mzW+9r6ZCa7diADrHfu3Fll2dc+Qp+F0SYbVv/0009XWdYnIvLPydnn7IULF6b111xzTZVlfTbrc217B5ns2oF89s96X1ufPHjwYJW9//77VZZ9lmh7rivFT0YAAAAAAACdchgBAAAAAAB0ymEEAAAAAADQKYcRAAAAAABAp0b8AOu2gRvZ0JBsOMhABj5lg/FuvfXWtD4bpJIN4Rs7dmyVtQ2gzq4dyLDAbBDLnDlzqqxtAHWWZ4NQ+vv703pDqGBkahvYdPr06SrLBk5lA+wi8j6bDfa777770voZM2ZUWTZUNRtKnV3Xdk+9DlqNyPt09t4xkMfM6LMw+rR9/2ZDlLO+OpA17fLly6vss5/9bFqf9dps/Zlp67VZr8yyNtkgwGXLlvV0XZvs63fgwIH0Wr0WRqa2791sXZV9/2cDWCPyXjeQNW32mTzbO8jWtG19Luv9WZ9t+5pkr3X27NlVln0eiIg4efJklWXvZ21fU30WRqaB9JS2z7SZbO157bXXVtlnPvOZtD7bo508eXKVZf287bP7YPtstp6fOXNmlZ06dSqtz3pqNtQ6yz7uvq4EPxkBAAAAAAB0ymEEAAAAAADQKYcRAAAAAABApxxGAAAAAAAAnbrkYUQp5eullD2llPUfyf5tKWVHKeXVC//75W5vEwAAAAAAGKnqMeG1b0TEH0XEty7K/1PTNP9+yO9ogNqmf58/f77Ksknn2aTyiIiJEydW2fXXX19ld911V1rf19dXZZMmTaqyUkqVZdPX2/KsPnvtERHz5s2rsmwi/enTp9P6EydOVNnJkyd7rr+ak9qBy9fWU44fP15lx44dq7IJEyak9dOmTauyVatWVdnKlSvT+smTJ1fZuHG9vK3lvTMif5/IsrZ+lvXU/v7+nrKIiFOnTlVZ9pra3if0WRi52npt1heya7N1ZkTE9OnTq2z16tVVtnz58rS+116b9Z+sf0bkPWwgvTZbp2ePefbs2bQ++5oOhF4LI1Nbn80+v545c6bK2vYO5s+fX2Vr1qypshtuuCGtnzFjRpX1uqZt67NZnq1/B9Jns5565MiRtP7w4cNVln1OaOvTwMjU1mfPnTtXZVmfmj17dlqf9d/bbrutyrLeGxExa9asKss+u2e66rPZfkh2T0ePHk3rDx06VGXZuj3by/24+7oSLvmTEU3TPBcRB67AvQAAAAAAAKPQYGZGfLmU8vqFv8YpP7oCAAAAAAA+8S73MOK/RMSqiLgjInZFxH9ou7CU8mgpZV0pZd3evXsv8+kAaKPPAnRPrwXolj4L0C19luHgsg4jmqb5sGmac03TnI+IP46Iez7m2q82TbO2aZq12cwCAAZHnwXonl4L0C19FqBb+izDQW9TkS5SSlnUNM2uC7/99YhYP3S3NDBtAzey4SjZIJRsiElEPsRq8eLFVbZw4cK0PhtEkg2hyoabtA1HaRu4erHstUfkg0yywVRtQ/2ygavZsMC2ITC93j8wvLQNocp6Qjbsr22AdTZUNVsQZddF5L2mbbDzxdr6bBd27dpVZQcO5KOYsq9fX19flWWDDiN6f/3A8NPWa7PhnlOnTq2ybJ0Xka9/u+i1A1nTZrL6tq9Jdu3JkyerLBvsF5Gv87Ov6aJFi9J6vRZGpraekn3+zdavbXsHWZ9dsWJFT9e1PdeVWtO27adkz599nfbv35/WZ58Tsj2StjXtlVyrA0Onradk/Xf+/PlV1rbHmq1db7zxxiqbO3duWp/tffa6nh3sXmbb1yTbI87u8/Dhw2l9Npg6u9e2966ruZ695GFEKeXPIuKhiOgrpWyPiD+IiIdKKXdERBMRWyLidzu8RwAAAAAAYAS75GFE0zRfTOKvdXAvAAAAAADAKORn3wAAAAAAgE45jAAAAAAAADp1WQOsR4JsiHM2MCUbVhcRMWXKlCrLBvt1MexvsNoeMxuakg1CyYaoRPQ+rHrSpEkDui9geGsbuJQNpst6b9tgumyIXTaANevHEXmv6nXgVNtr6rVPtQ1APH78eJVt3LixyrIBgBF5T80GqLa99xj2ByPXQNZJ2bDTmTNnptdma92s17QNwM56bdZrruQ6Lxvq/c4771RZW6/N7rWvr6/KFixYkNYbYA2jS697B219NlvTZte2fU7udU17JWVfk/fee6/KsgGqbbKvSdvX1JoWRpesp2W9r60nZEOYsywbAN32XFe7z2Z7Evv27auytvVsJnufyYZ/R1zdPqvDAwAAAAAAnXIYAQAAAAAAdMphBAAAAAAA0CmHEQAAAAAAQKccRgAAAAAAAJ2qx4mPMAOZfp5NT8+mr0dE7Ny5s8pOnDhRZf39/Wn9jBkzqmywk9qzSetZdv78+bT+wIEDVbZ3794qO378eFo/YcKEKrvhhhuqbMqUKWn91Z5UD1xa1lPavnfHjKnPs6dNm1ZlfX19af3Ro0er7OTJk1XW1menTp1aZVeqz54+fTqt37BhQ5Vt3LixyrLXGZF/rR544IEqmzRpUloPjFxZT42ImDx5cpXNmTOnyhYsWJDWHzlypMoOHTpUZW3rv6vZa8+dO5fW7969u8refPPNKjt8+HBan/XQT33qU1WWfZ0jrGlhJBjImjbLs8+0bT2h1/Xr2bNn0/orZSB7B/v376+yrM9m6/mI/L3jnnvuqbK2vQNgZGpbz44fP77Ksj7RtneQ7cdma9y2Pjtx4sQ0vxKy3huRv3e8++67VZbt5Ubke9w333xzlc2bNy+tv5rrWT8ZAQAAAAAAdMphBAAAAAAA0CmHEQAAAAAAQKccRgAAAAAAAJ0a8QOs22SD6VasWFFlTz/9dFqfDV3JhqPs2bMnrc+GW/U6HKRtuEk2XOrMmTNVlg2bioj49re/XWUvvPBClZ06dSqtv/XWW6vsl37pl6osG3QdYdgfjDbTp0+vslWrVlXZG2+8kdaPHTu2yrKhqtmg0oiIGTNmVFk2xCnT1mezgVfHjh2rsmxQdUTEf/7P/7nKsmF/bQO0fuVXfqXK7r333ipre536LIw+s2bNqrJbbrmlyl577bWeH3Pfvn1Vtm3btvTa2bNn9/y4F2vrtdlg6tOnT1dZW///r//1v1bZc889V2VtQwzvvPPOKvuN3/iNKmvr1XotDH8D+T6dNm1alWVr2tdff73nx8w+k2f7CRH5EOe2IbC9yvYOsp7YNhj1T/7kT6rs+eef7+l5IiJ+4Rd+ocqyda69A/hkyPYOVq9eXWWvvvpqWp+tKbN1YlufnTx5cpVl+xG9PndbnvXZbFB1RMQPfvCDnrLjx4+n9dke9z/4B/+gyrL98QgDrAEAAAAAgFHMYQQAAAAAANAphxEAAAAAAECnLnkYUUpZWkp5upSysZSyoZTyzy/kc0opT5ZS3rnwz8v/C2UBAAAAAIBRq5dJn2cj4l82TfOzUsr0iHi5lPJkRPx2RDzVNM0fllK+EhFfiYh/3d2tDkw28GnmzJlVtmjRorT+rbfeqrJsCGs2ADoiH47S19dXZdnAkxMnTqSPuWvXrirbsWNHlWWDpSIivvvd71bZ4cOHqywbChsR8Xf+zt+psjVr1lRZr0NggJGhbYBeNgjp2muvrbK2Pvviiy9W2csvv1xlS5YsSeuz/jlnzpwqywbrHT16NH3M9evXV1k2FLat92fvE9kA1M9+9rNp/aOPPlpl2fBaQ/1g9BlIr12+fHmVLVu2LK3/0Y9+VGWvvPJKlV1zzTU939fChQvTay/WNnDv/fffr7L33nuvyrL3iYiIp556qspOnTpVZfPnz0/rf+d3fqfKbrjhhiqzpoXRpW39lA1RzvrHvHnz0vps/ZplN910U1o/bly9LZMN1c7Wvv39/eljZnsHH3zwQZU98cQTaf1jjz1WZdk+xdKlS9P63/u936uy7DOBNS2MLm3f0+PHj6+ybI+0bY3Za5/N9igj8j4/derU9NqLZWvMiIgDBw5U2f79+6vsueeeS+u/9a1vVdmHH35YZW0DqH/jN36jyu69994qy95jrrZL/mRE0zS7mqb52YVfH42ITRGxOCJ+NSK+eeGyb0bEr3V1kwAAAAAAwMg1oJkRpZTlEXFnRLwYEQuapvl/x+27I2LBkN4ZAAAAAAAwKvR8GFFKmRYR/ysi/kXTNEc++u+an/+8YP0zgz+ve7SUsq6Usm7v3r2DulkAavosQPf0WoBu6bMA3dJnGQ56OowopYyPnx9E/GnTNN+5EH9YSll04d8viog9WW3TNF9tmmZt0zRr2/6ORQAunz4L0D29FqBb+ixAt/RZhoMVS+XDAAAgAElEQVRLHkaUn08f+VpEbGqa5j9+5F89FhG/deHXvxUR3xv62wMAAAAAAEa6XkZq3xcRX4qIN0opr17I/k1E/GFE/M9Syj+OiK0R8fe7ucWPN5BJ7TNmzKiyZcuWpfUTJ06ssk2bNlXZ1q1b0/qnnnqqyubMmVNl2VTzY8eOpY+ZTVXfvHlzlWXT2yPyCfDZpPp/+A//YVr/m7/5m1U2ZcqU9FpgZMp6alufzb7/lyxZUmVLly5N69etW1dlGzdurLL3338/rf/e9+oz8KzPZvd/5MiRKouI2LFjR5Xt3r27yk6ePJnWZ+8dn//856vsX/2rf5XWX3vttVWWvU+0/TcBRp+sr1xzzTVVtnr16rT+Zz/7WZVt2bKlyr72ta+l9b2uaceMqf+M0/Hjx9PHzPpqlrX16p//DbF/3fXXX19lv/u7v5vW/62/9beqbNKkSem1wOjRtn7K+mxfX1+VLVq0KK0/d+5clf34xz+usvfeey+tv+mmm6os67PZ8xw8eDB9zO3bt1fZ22+/XWUHDhxI67Pnuv3226usbU17zz33VNmECROqzJoWRpe27+ns+z/rc217tK+++mqVZWvcXbt2VVlExM0331xl2U+GnD59usra+mS2d/DWW29VWdaPIyL6+/urbMGCehzz3/t7fy+t/yf/5J9U2dSpU9Nrh5tLHkY0TfN8RLS9Q9Q7LAAAAAAAAB/R8wBrAAAAAACAy+EwAgAAAAAA6JTDCAAAAAAAoFO9DLAeNrJhddmwvLZ85syZVZYNVorIB1NnQ/Q++OCDtD4bwpcNkD579mxPWUTE+fPnqyx7ndkAroiI6667rsr+0T/6R1X2pS99Ka2fNWtWT89vCBWMXAPps9lg5WzgUjbAOSIfLvXkk09W2d69e9P6PXv2VNmZM2eqLHtN2VC+NmPHjq2ybNhVRMSv//qvV9nv//7vV9mqVavS+vHjx/d8X8DoMpA17dy5c6vsoYceSus//PDDKvv+979fZdkQvoiIffv2VVk23C/rqwPptdn6ccqUKem1d911V5X903/6T6vsl3/5l9P67HGz57emhZErW/9la7q2POuzn/70p9P6LVu2VNkPf/jDKtu4cWNav2nTpirLBptm+wTZ2jei9zX99OnT0/rPfe5zVfbP/tk/q7K2r0m2J6Gnwugy2D3a2bNnV9natWvT+mzv9dlnn62y1157La1//fXXq+zEiRNVlq1xs34cke/RZn1uIHu0X/ziF6vsd37nd9L67Os3UvZo/WQEAAAAAADQKYcRAAAAAABApxxGAAAAAAAAnXIYAQAAAAAAdGpEDbDOhm5kA1Mi8sGq06ZNq7Jly5al9Y888kiVZcPussFUERFvvfVWlWUDsAcy2G/SpElVNn/+/CrLhk1FRPze7/1ela1Zs6an54loH0QDjB4DGW6UDVueOXNmla1evTqtz4Y9Z/VtfXbbtm1VdujQofTai7X1uWww9d13311lf/fv/t20/uGHH66yGTNmVFnbAEUDVIGLZWvabE26YsWKtP5v/+2/3VP9k08+mda//fbbVXby5Mkqy9a0bf0re/5rrrmmyrL1eES+ps3W9BMmTEjrrWlh9BvI3kG2ps3Wb6tWrUrrf+mXfqnKsv7zzDPPpPXZYNZsYGqvw1Ij8r2PbFjqr/3ar6X1v/3bv11lCxYsqLLsa9d2X9a0MLoMts9OnTq1ypYvX57WZ5+zs8d87rnn0vpsPXv06NEqO3v2bFqfyfp8X19flT300ENp/Ze//OUqu+WWW6qsbe+ibU9hJLASBwAAAAAAOuUwAgAAAAAA6JTDCAAAAAAAoFMOIwAAAAAAgE45jAAAAAAAADpV2iadd2Ht2rXNunXrrshz9fq62q47d+5clR0/frzK9u7dm9a/8847VfbSSy9VWTa9fdasWeljPvjgg1WWTZrPprdH5BPYSyk9ZR+XXy1r166NdevWDa+bgqtspPfZkydPVtmhQ4fS+j179lTZzp07q2zcuHFV1tYnV6xYUWVTp06tsgkTJqT1Y8eOTfOLDbd++nFKKS83TbP2at8HDCdXstdmsr46kF574sSJKtu/f39av2XLlip7+eWXq+zUqVNVNnfu3PQxP/OZz1TZ4sWLq2z69OlpfdaDB9JXh1sPtqaF2kha0549e7bKsvXrrl270vps72Djxo093dM111yT5p/+9Kd7ujZb50ZEjB8/vsoGsncw3OizUBvpffbgwYNV1tZn33jjjSr72c9+VmX9/f1VNmPGjPQx77vvviq76aabqmzhwoVp/eTJk6tsJO/RRvS+d+AnIwAAAAAAgE45jAAAAAAAADrlMAIAAAAAAOjUJQ8jSilLSylPl1I2llI2lFL++YX835ZSdpRSXr3wv1/u/nYBAAAAAICRpp7qWTsbEf+yaZqflVKmR8TLpZQnL/y7/9Q0zb/v7vYuX6+DPNquGzOmPqfJBkvPnDkzrb/uuuuq7JFHHhnUPQEMJ1302WxYXtvAqGXLlvX0/ACjzUCG22W9Nlu/tq1pV65cWWWf+9znLnWLACPGYNe0EyZMqLL58+f3lEVE3H777T09P8BI1UWfXbBgQU9ZRN5nv/SlL1VZNkDbHu3Qu+RhRNM0uyJi14VfHy2lbIqIxV3fGAAAAAAAMDoMaGZEKWV5RNwZES9eiL5cSnm9lPL1UsrsIb43AAAAAABgFOj5MKKUMi0i/ldE/IumaY5ExH+JiFURcUf8/Ccn/kNL3aOllHWllHV79+4dglsG4KP0WYDu6bUA3dJnAbqlzzIc9HQYUUoZHz8/iPjTpmm+ExHRNM2HTdOca5rmfET8cUTck9U2TfPVpmnWNk2zdt68eUN13wBcoM8CdE+vBeiWPgvQLX2W4eCSMyPKzyd1fC0iNjVN8x8/ki+6ME8iIuLXI2J9N7c4vBlkAgAAAAAw/Ax2gDZD65KHERFxX0R8KSLeKKW8eiH7NxHxxVLKHRHRRMSWiPjdTu4QAAAAAAAY0S55GNE0zfMRkR0NPT70twMAAAAAAIw2PQ+wBgAAAAAAuBwOIwAAAAAAgE45jAAAAAAAADrlMAIAAAAAAOiUwwgAAAAAAKBTDiMAAAAAAIBOOYwAAAAAAAA65TACAAAAAADoVGma5so9WSl7I2Lrhd/2RcS+K/bkV8Zoe03D/fVc2zTNvKt9EzCc6LMj0nB/TXotXOQjvXa4f/9eDq/pytNn4SLWtCPScH5N+ixcRJ8dkYb7a+qp117Rw4i/9sSlrGuaZu1VefKOjLbXNNpeD3zSjMbvYa8JGE5G4/ev1wQMN6Pxe9hrAoaT0fj96zUNX/6aJgAAAAAAoFMOIwAAAAAAgE5dzcOIr17F5+7KaHtNo+31wCfNaPwe9pqA4WQ0fv96TcBwMxq/h70mYDgZjd+/XtMwddVmRgAAAAAAAJ8M/pomAAAAAACgUw4jAAAAAACATjmMAAAAAAAAOuUwAgAAAAAA6JTDCAAAAAAAoFMOIwAAAAAAgE45jAAAAAAAADrlMAIAAAAAAOiUwwgAAAAAAKBTDiMAAAAAAIBOOYwAAAAAAAA65TACAAAAAADolMMIAAAAAACgUw4jAAAAAACATjmMAAAAAAAAOuUwAgAAAAAA6JTDCAAAAAAAoFMOIwAAAAAAgE45jAAAAAAAADrlMAIAAAAAAOiUwwgAAAAAAKBTDiMAAAAAAIBODeowopTyN0spb5VS3i2lfGWobgoAAAAAABg9StM0l1dYytiIeDsivhAR2yPipxHxxaZpNg7d7QEAAAAAACPduEHU3hMR7zZNszkiopTyPyLiVyOi9TCir6+vWb58+SCeEv7Kli1bYt++feVq3wcMJ/osQ+3ll1/e1zTNvKt9HzCc6LUMJWtaqOmzDCV9Fmr6LEOt172DwRxGLI6IbR/5/faIuPfjCpYvXx7r1q0bxFPCX1m7du3VvgUYdvRZhlopZevVvgcYbvRahpI1LdT0WYaSPgs1fZah1uveQecDrEspj5ZS1pVS1u3du7frpwP4xNFnAbqn1wJ0S58F6JY+y3AwmMOIHRGx9CO/X3Ih+2uapvlq0zRrm6ZZO2+ev+UBYKjpswDd02sBuqXPAnRLn2U4GMxhxE8j4vpSyopSyoSI+M2IeGxobgsAAAAAABgtLntmRNM0Z0spX46IJyJibER8vWmaDUN2ZwAAAAAAwKgwmAHW0TTN4xHx+BDdCwAAAAAAMAp1PsAaAAAAAAD4ZHMYAQAAAAAAdMphBAAAAAAA0CmHEQAAAAAAQKccRgAAAAAAAJ1yGAEAAAAAAHTKYQQAAAAAANAphxEAAAAAAECnHEYAAAAAAACdchgBAAAAAAB0ymEEAAAAAADQKYcRAAAAAABApxxGAAAAAAAAnRp3tW/gamuappP68+fPV9nZs2er7NSpUz1lAzFx4sQ0Hzt2bJWNG1f/XyC7ri0vpfR8XwO5Fhj9eu2/XfTZ06dPD+qe9FlgpBjsWrfXXpv11TNnzqSPmfWq7D7Hjx+f1o8ZU/95qqx/6rXAULraewcnT57sKRvI80+ePDm9Nlu/9ppF5H02691t9Fngowbbf8+dO9dTlu0dtK1nM9l9TpgwIb2217XraFzP+skIAAAAAACgUw4jAAAAAACATjmMAAAAAAAAOuUwAgAAAAAA6NSgBliXUrZExNGIOBcRZ5umWTsUNwUAAAAAAIwegzqMuOAXm6bZNwSP07lsqnnbRPYszyatnzx5Mq1///33q+yFF16osjfffLPK9u3Lv5zZc40fP77KFixYkNZff/31VbZkyZIqu+uuu9L6uXPnVlk2FX7cuN7/b3U1p7cDQ28gfTaT9dn+/v702qzP/uQnP6myDRs2VNmePXvSxzxx4kSVZT1tsH32nnvuSev1WaAXA+mrva5pT506ldZv3769yl566aUqW79+fZW19dpsTTt27NgqmzdvXlp/3XXXVdnChQurbO3a/M9J9fX1VVnWa7N1dhu9FkaXwa5pz549W2UDWdNmewcbN26ssoGsabM+O3/+/LT+hhtuqLJsTfvpT386re+1z1rTwifX1V7P/vSnP62ybD27e/fu9DGznj5mTP0XELX12VWrVlXZokWLquzuu+9O60dyn/XXNAEAAAAAAJ0a7GFEExE/KKW8XEp5dChuCAAAAAAAGF0Gexhxf9M0n4qIRyLi90spD158QSnl0VLKulLKur179w7y6QC4mD4L0D29FqBb+ixAt/RZhoNBHUY0TbPjwj/3RMSfR0T1l2A3TfPVpmnWNk2ztu3vfQXg8umzAN3TawG6pc8CdEufZTi47AHWpZSpETGmaZqjF379cET8uyG7sx4NduDJ+fPn02tPnz5dZTt27KiyZ555Jq1/7LHHqmzTpk1Vdvz48Z6eu012/1OmTEmvnTVrVpVlw6rbnj8bTpU1r2xgS0Q+MAsYuXod7NfWZ8+cOVNlu3btqrIf/vCHaf33vve9KssG+2V9tm2wVSYbjDV16tT02qzP3nHHHVWWDRWMiHjggQeqLBt4pc/C6NPVmjYbopoN4nvuuefS+mxN+8Ybb1TZkSNHqmywa9q2Xjtz5swqu+2226rs8OHDaf2DD1Y/zJ0ODGzrtQMZBAgMf72uadv6dLam/fDDD6usrc9+97vfrbKszx49erTK2vpsr+8TbXsHWZ/N1rTZa4+IuP/++6vMmhY+ubros9lPdrzwwgtp/Xe+850qe/3116ssWzu27R30ev+DXc9ma+yIwa9nr2afHcxKekFE/PmFSdvjIuK/N03zv4fkrgAAAAAAgFHjsg8jmqbZHBG3D+G9AAAAAAAAo9BgB1gDAAAAAAB8LIcRAAAAAABAp0bt9LVeBzb19/en9Zs3b66yb37zm1X2l3/5l2n9wYMHqywbIDhx4sQqmzZtWvqY2XCpbLBqNqy17Z6ywVgzZsxI67NBKNn99/X1pfXAyNQ2RKrXPts28Cnrs1/72teqrK3PHjp0qMqyPjthwoQqaxvWN2nSpCobyHtH1mezwVhtQ6yywX7jx4+vsgULFqT1hv3B6DPYXrtly5Yq+8Y3vlFljz/+eFp/4MCBKsuGCGa9NuupbfmFOXR/TVuvzfr/hg0bqqyt12Y9NOu111xzTVqf/TfJ7h8YubLv87Y+u3379ir71re+VWWPPfZYWr9v374qy/ps9tm7rc9l+WD3DrI17fTp09P6rH9m9z9v3ry0HhiZBrJ3kGWnT59O67dt21ZlA+mz2bDrrM9m68Gsd0W07ylcbCDr2fXr1/f8PFn/HMh69mruHfjJCAAAAAAAoFMOIwAAAAAAgE45jAAAAAAAADrlMAIAAAAAAOiUwwgAAAAAAKBT4672DVxJZ8+erbKDBw+m1z7xxBNV9vzzz1dZNpE9ImLcuPpLu2jRoipbs2ZNlV177bXpY44ZU58dnT9/vso+/PDDtD7LT548WWXbt29P699+++0qy6ayz5o1K63PJrWXUtJrgZEp67P79+9Pr33ssceq7Nlnn62ytj6b9ZT58+dX2erVq6ts2bJl6WNmvTuzZ8+envPjx49XWVuf3bhxY5UtWbKkyubOnZvWZ1+TLANGtqzXHjhwIL328ccfr7JnnnmmytrWj1kPmTdvXpXdcMMNVbZ06dL0MSdOnNjT87S9f+zbt6/Kjh49WmVtr+ndd9+tsuxes/eUiN7fK4DhpWmanvOszx45ciSt/8EPflBlTz31VJXt3Lkzre91TXvTTTdV2YoVK9LHHD9+fJWdO3euynbv3p3WZ/nhw4er7IMPPkjrN2zYUGWLFy+ustmzZ6f19g5g9BvIHu33v//9KnvyySerrK3PZv0j+0ydrWeXL1+ePma2ns3WiANZz2Z9tu01bdq0qcqyvYO+vr60/mruHfjJCAAAAAAAoFMOIwAAAAAAgE45jAAAAAAAADrlMAIAAAAAAOjUJ2r62unTp6vszTffTK/9yU9+UmXZcKa2AXbXX399lX3uc5+rsptvvrnK2garTpgwocrOnDlTZe+//35a/9Zbb1XZG2+8UWXZsNWIfDjKpz71qSrLhtBE5PcPDH9tw+KyYX+nTp2qstdeey2tf/7556ts27ZtVdY2ROnaa6+tsi984QtVduutt1ZZ2xCqbNjf+fPnq6xtWF/2npK9/rbBXFn9XXfdVWXZAMAIfRZGsoH02mxNmw0LjRh8r83WpZ///OerLBusunLlyvQxJ02aVGVjxtR/RmrHjh1p/dtvv11lr7zySpUdOnQorX/nnXeq7I477qiy7D0tIh9YCAx/A+mz2efsrPdERDz33HNVln0mb+uz2br04YcfrrLbbrutyrL1cETvewdbtmxJ6zdu3Fhlr776apVlw1Yj8vektWvXVtmiRYvSemtaGJkGu57N9igjIn74wx9W2ebNm3t+/myw89/4G3+jym655ZYqW7VqVfqYkydPrrKsz+/atSutz9aj69atq7Js0HVEvseb7TFnrz0iX49fKX4yAgAAAAAA6JTDCAAAAAAAoFMOIwAAAAAAgE5d8jCilPL1UsqeUsr6j2RzSilPllLeufDP2d3eJgAAAAAAMFL1MsD6GxHxRxHxrY9kX4mIp5qm+cNSylcu/P5fD/3tXb5z585VWTaY+eWXX07rs0Ei2cCV+fPnp/XZcKZPf/rTPdXPnp2f7WTD8k6cONHTdRH5ENZsiGo21DAiH7ry4YcfVtl1112X1gMjU9b7IvI+e/To0Sp78cUX0/pe++ycOXPS+qynPvjgg1W2YMGCKps1a1b6mNkQp/7+/iqbPn16Wp85cOBAlWUDBCPyPpsN5soGUwEj20B67bFjx6qsrddmA1ezx2zrtffee2+Vffazn62yhQsXVtncuXPTx8wG/mVDDKdOnZrWZ8MJB9Jrs/Xr1q1bqywbyg2MXG19NvucnH3Ofumll9L6TZs2VVnWZ+fNm5fWf+Yzn6my+++/v8qyNW3b3kE2APrkyZNVlvXjiPz+sz773nvvpfVZn/3ggw+q7MYbb0zrgZFpIOvZI0eOVNmPfvSjtD7rs1nvblt7Zn022ztYtGhRlbWtkadMmVJl2dqzbe8g27s9dOhQT48ZEbFnz54qy9b9t912W1rf9t/qSrjkT0Y0TfNcRFz8rvOrEfHNC7/+ZkT82hDfFwAAAAAAMEpc7syIBU3T/L8/vrk7IuojegAAAAAAgBiCAdbNz3+uo/VnO0opj5ZS1pVS1u3du3ewTwfARfRZgO7ptQDd0mcBuqXPMhxc7mHEh6WURRERF/5Z/0VVFzRN89WmadY2TbO27e9IBODy6bMA3dNrAbqlzwJ0S59lOLjcw4jHIuK3Lvz6tyLie0NzOwAAAAAAwGgz7lIXlFL+LCIeioi+Usr2iPiDiPjDiPifpZR/HBFbI+Lvd3mTlyOb1L5v374qe+utt9L6bKp7pq+vL81vvPHGKlu4cGGVTZo0qcrGjx+fPuaYMfXZUXbt1KlT0/rly5dX2datW6ts8+bNaf3hw4erLJvUfv/996f1wOhy9uzZKtu1a1eVtfXZEydOVFkppcra/sTGLbfcUmVLliypsokTJ1ZZ1nsjIsaOHVtlEyZM6Om6iIgVK1ZU2XvvvVdlb775Zlp/4MCBKsv6LPDJ0Wuvbesr2Zr253/L6l/XtqZds2ZNlS1durTKsr6a9c+I3te02XURea9fsKAeYdf2Ncn+WoJ33nmnyn7lV34lrQdGl6zPZnsHmzZtSuuzPpv1r2w/ICLitttuq7Ksz2Y9ta3PZmvVrM9OmzYtrV+5cmWVbdmypcra1qn79++vsuwzwcMPP5zWZ+9TwMh15syZKtu+fXuVrV+/Pq0/duxYT88zf/78NL/zzjurLPvsPti9g8y4cfnW++LFi6ts2bJlVbZx48a0Pnufevfdd6usrZ9ezT57ycOIpmm+2PKvPj/E9wIAAAAAAIxCgx5gDQAAAAAA8HEcRgAAAAAAAJ1yGAEAAAAAAHTqkjMjhru2gRvZAOtsiNIHH3yQ1p88ebLKsqEjbcNRZs+eXWXZYOnsMdte06lTp6osG7bVNtjl+PHjPdVnrz0i4tChQ1WWDQDs7+9P69sGawPDW1tPyvrHzp07qywbdheR94psCF82qDQiHwI42D57+vTpKjt//nyVZcO3Py6/WNbP2+qzodZtzzNnzpyenh8Yfgbbazdv3pzWZ+u6bIhp22DVuXPnVlk28DR7zDZZr81ef9uaNFvTZo/Z1iuPHj1aZXotjH4D2TvIBoMOZE2b9cS2Ne2iRYuqLFvTZkOx215TNix2IH0266nZsNbsa9f2uNnXtO35Z86cmebA8DaQnvTee+/1lEXkn5+zwdLLly9P65cuXVpl06dPr7Js7yDrvRH5Gr2UUmVtn/2zPpvVZ88Tkb/3ZPve2V5uRMQ111yT5leCn4wAAAAAAAA65TACAAAAAADolMMIAAAAAACgUw4jAAAAAACATo34AdZtskEgzz33XJVt3bo1rc+Gq2TDqhcsWJDWL168uMqyoScTJ06ssmxYakQ+yCTLsseMyIdgZfXZa4/IB2NnQ7zahrMAI1PbEKpsYNKzzz5bZbt27Urrs0FM2QDVtsFK2RDAbLBeNhS7bdhe23Cqi7X12WwIVjbAsO1rmg1L3bZtW5VlX/uPe1xg+BtIr3366aerbMeOHWl91mvnzZtXZW1r2mXLllVZ1muzvtg2cC9bf2ayIYIR+cDCTNuaNBtgnX0maBusqtfC6JLtHWR9tm2Adfb5ORuWeu2116b12d5Br322bU2b9aksmzx5clqfDZCeMmVKem0mW9Pu3Lmzytr6tD4LI1Pb9262n5j12T179qT12ZoyW7sOZIB19jm9i72D7DEj8p6arXHb1s3ZOjVbz2Zf+4ir22f9ZAQAAAAAANAphxEAAAAAAECnHEYAAAAAAACdchgBAAAAAAB0asQPsG4buJENQsqGe7QNi84GkSxatKjK7rrrrrQ+G3adDZDOBvNlw6ra8uw+215TNvBqzpw5VZYN8IrIv6bZIJTjx4+n9YZQwcg0kKGqWZ9tq8/6XzaU+p577knr+/r6qiwbwtfrAMC2a7P7bHtN2XCqbFBs2xCsbDBX1lOz4asfd1/A8Nf2/Zv11YGsabO+lg1Lbeu12XDAbOBe1ivbBk332mvbXlPWa2fPnl1lbWvabNhstqbVa2F0GUifzb7/29ZvWU/LhqXefffdaX3Wv7L+mT1P22DUbJ9gIH02Wytn7wdtX1NrWvhkauspve4dttVnw6ZXrFhRZffdd19an/XZbO8gGxbd1meznty2n5s5ceJElWV7B1k/jcj3aLPH3L9/f1pvgDUAAAAAADBqOYwAAAAAAAA65TACAAAAAADolMMIAAAAAACgU5c8jCilfL2UsqeUsv4j2b8tpewopbx64X+/3O1tAgAAAAAAI9W4Hq75RkT8UUR866L8PzVN8++H/I4GqG3Selt+sZkzZ6b5rFmzqmzNmjVVdvvtt6f1c+fOrbJsAns2qX3MmPyMKJvKntW3vfbsNWUT6U+ePJnWHz16tMqOHDlSZf39/Wn91ZzUDly+tu/drNdk/WvatGlp/Zw5c6rspptuqrJbb701re+1p3XRZ9u+JjNmzKiycePqt9q2Pnv8+PEqO3XqVJWdOXMmrddnYeQabK+dPn16Wp+tSW+++eYqu/POO3uuz9a0mYH02uzatjVttn7PevWJEyfS+mPHjvV0rV4Lo0tbT8m+17Nr2/psX19fld1www09ZRH5+rHXNW2WRQy+z06dOrXKsjVttk6NyNe0+iyMfm3fu+fOneupvm3vYPbs2VWW7ROsXr06re/1c3pmIH227drMpEmTeqrP1q0R+R7txIkTq+zs2bNp/dXss5f8yYimaZ6LiANX4F4AAAAAAIBRaDAzI75cSnn9wl/jVB9RAQAAAAAAxOUfRvyXiFgVEXdExK6I+A9tF5ZSHi2lrMjmh7EAABVMSURBVCulrNu7d+9lPh0AbfRZgO7ptQDd0mcBuqXPMhxc1mFE0zQfNk1zrmma8xHxxxFxz8dc+9WmadY2TbN23rx5l3ufALTQZwG6p9cCdEufBeiWPstw0Nu0jouUUhY1TbPrwm9/PSLWD90tDUzbwI1sQEc2LDUbghKRDxK59tprq2zBggVp/eTJk6us1yFSAxl4kmmrz4YNZlnbYNVsOFU28GXKlClpfdsQQ2B4G8gQqoH02WwI4NKlS6ssGwoYkffpXodIDaQfZfVtw/567fPZUL+IvM9mAwyz4a1tzwWMDAPptdlQ6az/RuT9YuXKlVW2cOHCtD7rtdn6byCDVQe71s2eP8uOHDmS1vfaa2fNmpXW67UwMrWt37K9g2ydmg1Abbt28eLFVda2Js4Gjl6pNW2b7Pkz2QDViHxPIXs/aRtWq8/CyDSQPputZ7MsImLJkiVVtmrVqipr67PZ3mev+7GDXc+2rfGz58+u3b9/f1rf399fZdn7SfZ+FNH7AO8uXPKZSyl/FhEPRURfKWV7RPxBRDxUSrkjIpqI2BIRv9vhPQIAAAAAACPYJQ8jmqb5YhJ/rYN7AQAAAAAARiE/+wYAAAAAAHTKYQQAAAAAANCpqzetomPZ0I9sOEjbEKpsAHU2xG7q1KlpfTYEbyCDUAajbThKNkhm3759PV0XkX/9smHVbUOounitwPCSDUEayADrbNDqcOyzbbL+uWvXrirLBnhF5PeafZ0MVYVPtqz/tQ38y9a62bUD6bVXqte09e+s1+7evbvKsuHfbY+brV/1WvhkaPv8e7FsTdaWZ/sJ2WfniJGzpt2+fXuVta1psz7Z69q/rR4Y/gYy7DkbKt3X15fWZ70iy7IBzhH5PsXV3qPM+uyWLVuq7Pjx42l9dv/Zun/hwoVp/dXsszo8AAAAAADQKYcRAAAAAABApxxGAAAAAAAAnXIYAQAAAAAAdMphBAAAAAAA0Kl6nPgI0zb9PJsKPnny5Cprm9R+8ODBKjtx4kSVnTlz5lK3+P91Mam9aZoqyyayR0QcPny4ynbs2FFlx44dS+vHjx9fZTfeeGOVZRPtI67+pHrg8rR9744dO7bKpk2bVmXz589P67OelPWf/v7+tH7KlClVdrX77KFDh6ps69atVXb06NG0fsKECVV2yy23VJk+C6PPQHpt1v/aem2vfbVtTZs9VxcGu6bNem22do/I17S33nprlc2aNSut12thZMr2CCJ677Nz585N67OelK31Tp06ldYPxzVtth+yefPmnq6LiJg4cWKV3XTTTVVmTft/27u32CrLPY/jv/+GQjmXUqylA6KGs4diZKth1PEQwuyYKBEVBMRosr1wFBMvxngzczPJvphx5mYyiRPN9sJ4xLi9mESBcFATlRaKKPXEAIopyEEB5ST6zEXXTpDn/w5rsfqurvfp95PsUH706XpfdP18up69+gfSktWzjY2NUeY9/7P2s15/et97Z+1nvcevlayePXr0aJT19PREmfffGMl/7WDu3LlRlvW690D2LO+MAAAAAAAAAAAAueIwAgAAAAAAAAAA5IrDCAAAAAAAAAAAkCsOIwAAAAAAAAAAQK4KP8A6y6hRo6Js+vTpUfbBBx+4671BHocPH46yQ4cOueu9Ia7lDgfxBktJ/tCTM2fORFnWcJPXX389yjZt2hRlWYO1vGHVd911V5R5w6okhlABRZX13B0zZkyUeYPpurq6yv663hC8rJ71Bl7Vqme9YVmS9Morr0TZxo0bo+z06dPueq9nFy9eHGX0LDB4eHvKGTNmRFl3d7e73hsk6HVYVq95j+8Ne61EuV3rDfaTpJdffjnK3n333SjL6lrv7+++++6LMm8woETXAqnx9rReT2Ttab1O8147OHjwoLt+7NixUZbHntYb7Jo1gPqll16Ksg0bNkRZ1msHHR0dUea9dkDPAoOD13OzZs2Ksh07drjrvU777rvvoiyr00aOHBlltdrPHjt2zF3/6quvRtnatWujrJL97PLly6OsHl874J0RAAAAAAAAAAAgVxxGAAAAAAAAAACAXHEYAQAAAAAAAAAAcnXewwgzm2xm681sh5l9amarSnmzma0xsy9Lv47P/3IBAAAAAAAAAEDRlDPA+oykJ0MIW8xsjKQuM1sj6UFJ60IIfzKzpyQ9Jekf87tUX9bAjaFD41trbm6OskmTJrnr33vvvbIeyxuKLfmDmMaPj89rvIFTJ06ccL/m/v37o2zfvn1R5g2WkqTXXnstyrxhhd7wb0m69957o+yKK66IsmqHwACoL5X07IQJE6Isq2fff//9KPMGrW7evNld7w1iKrdnjx8/7n5Nr1O97l2/fr27fvXq1VF25MiRKPMGJUrS0qVLo2zOnDlRRs8C6amka1taWqKstbXVXe8NXN2+fXuUXXnlle76xsbGKPM6rJKu9QYOetmaNWvc9d7Av0q61hvux54WSF9WzzY0NESZ16ltbW3uem9P293dHWXTpk1z13uvHXivXXh++uknN+/t7Y2yvXv3RtnGjRvd9W+++WaUeUNYm5qa3PXLli2LspkzZ0YZPQukJatnve/dvU69+OKL3fWdnZ1Rtm3btijzhmJLfs96Q7UHej979OjRsq5TklauXBllRdnPnvedESGE3hDCltLHxyT1SGqXdKekF0qf9oKku/K6SAAAAAAAAAAAUFwVzYwws6mS5kr6UFJrCOGvx+37JPn/dywAAAAAAAAAADColX0YYWajJa2W9EQI4TfvGwl972OJ38vSt+6PZtZpZp0HDhyo6mIBADF6FgDyR9cCQL7oWQDIFz2LelDWYYSZNajvIOLFEMIbpXi/mbWV/rxNUvyDsSSFEJ4NIVwbQrh24sSJ/XHNAICz0LMAkD+6FgDyRc8CQL7oWdSD8x5GWN/0keck9YQQnjnrj96S9NdpGSsl/aX/Lw8AAAAAAAAAABTd0DI+Z76kFZK2m1l3KXta0p8kvWpmD0vaI+nefC7x/5c1qb2hoSHKmpqaouySSy5x13/00UdRtnXr1ijbvXu3u96b4D5hwgT3c8/lTU+XpN7e3ijbuXNnlHnT2yXp1KlTUeZNr7///vvd9cuXL4+ykSNHup8LIH1ez7a0tERZVs92dXVF2bZt26Jsz5497vq33347yrye7/tJgr+V1bP79u2Lsl27dkXZwYMH3fWnT5+OskmTJkXZihUr3PXLli2LshEjRrifCyAtWXvaYcOGRVlzc3OUtbe3u+u9/Wt3d3eUffvtt+762bNnR9n48eOjzOu/w4cPu1/Te6w89rQPPPCAu97b09K1QPqyenb48OFR5u1pp06d6q7v7OyMsk8++STK9u7d66739rTlvnZw5MgRNy/3tYOsnv7555+jzLv/hx9+2F2/aNGiKGtsbHQ/F0A6KunZ1tZ49PDkyZPd9d7rBN4eN6tn58yZE2Xjxo2LMq/7vv/+e/drevvZr776KsoOHTrkrvf2zlOmTImyBx980F2/dOnSKPP2s1n/TAbSeQ8jQgjvScq68tv693IAAAAAAAAAAEBqyh5gDQAAAAAAAAAAcCE4jAAAAAAAAAAAALniMAIAAAAAAAAAAOSqnAHWdcMbQvq73/nnKV7uDTadN2+eu94bTP3DDz9EmTfYNCs/efJklP3yyy9R5g0xkaRff/01yrz79AbDSNKMGTOizBtWnTXsb+zYsWU9fj0ORwFQnjx69rrrrnPXf/3111HmDeHz+ljye9YbauoNoTpz5oz7Navt2enTp0eZ16lZA6zHjBlT1uPTs0CxVdK1Q4YMiTJvgHTWnnbPnj1RtmnTpijbsWOHu76npyfKTpw4EWXe/tXrZMm/f6/Xqu3arD2t17Xe49O1QHFVu6dtbm6Osvnz57vrvSGm77zzTpR988037npvT+z1p7d/9fa5Uvk96w07laSOjo4oe+ihh6LMG1QtSaNHj44y9rRAWqrtWW8/e8MNN7jrvZ7dsGFDlH322Wfu+s8//zzKjh8/HmVep+b1Gq03VNvr2SVLlrjrvZ4tSqfyzggAAAAAAAAAAJArDiMAAAAAAAAAAECuOIwAAAAAAAAAAAC54jACAAAAAAAAAADkqlADrL1BHN7AFEkaOjS+tVGjRkXZlClT3PULFy6MssbGxihbt26du/7LL7+MsnIHWGfxHn/ixIlRduutt7rrH3300SibOXNmWY8j+QMUAaSlkp5taGiIMq9np06d6q73etYb7rR27Vp3/c6dO6Os2p4dNmxYlFXSs4899liUzZo1K8qyhljRs8DgUO2e1hvAfNlll7nrb7vttrK+5saNG931u3btirIff/wxyirpWu+/H5V07eOPPx5lXtdm7WmzhisCSEe1e1pvMOill17qrr/jjjuizNsTr1+/3l3/xRdfRNmxY8eizBtgnWXkyJFR1t7eHmXeflySHnnkkSjz9vRZe1p6FkhftT1byX52wYIFUeZ97+wNtZb8/aw3wLra1w5aW1ujzNuLS9KqVauibNq0aVFWSc8ywBoAAAAAAAAAAEAcRgAAAAAAAAAAgJxxGAEAAAAAAAAAAHLFYQQAAAAAAAAAAMgVhxEAAAAAAAAAACBXQwf6AqqVNSncmyruTTpvaWlx18+fPz/KrrrqqihbsmSJu76npyfKNm/eHGUnT56MsqamJvdr3nTTTVHmTZrPuqfGxsYo8/7+sv5OizKVHUD/quS5X0nP3njjjVHm9ezixYvd9R9//HGUdXV1Rdnx48ejrLm52f2at9xyS5TNmDEjyi666CJ3PT0L4EJVu6dtbW111y9YsCDKrrnmmii7++673fVer27dujXKTp06FWVZXXvzzTdHmdf/bW1t7voRI0ZEGV0L4Hyq3dNOmDDB/VzvtYOOjo4oW7Fihbt+9+7dUbZly5Yo8147yLqm66+/Psra29ujbNy4ce764cOHR1klf3/0LDA4VduzWd9ne9+nX3311VF2zz33uOu7u7ujbNu2bVFWyX7Wu6aZM2dGWSWvHXj7/ixF7lneGQEAAAAAAAAAAHLFYQQAAAAAAAAAAMgVhxEAAAAAAAAAACBX5z2MMLPJZrbezHaY2admtqqU/7OZfWtm3aX//SH/ywUAAAAAAAAAAEVTzgDrM5KeDCFsMbMxkrrMbE3pz/49hPCv+V3ehSt3kEfW55U7sCprYJQ3tGTRokVVXRMA1JM8enbixIllZZI/sCprMGC51wQA9aaSwcyeIUOGRJk3xHTSpEnuem8IarnoWgBFUO2e1hs42tTUVFYmSZdffnmU3X777WVdEwAUQbU9O3z48Chra2srK5OkefPmXfA1of+d9zAihNArqbf08TEz65EUfwcDAAAAAAAAAADgqGhmhJlNlTRX0oel6B/M7GMze97MxvfztQEAAAAAAAAAgASUfRhhZqMlrZb0RAjhqKT/knS5pA71vXPi3zLW/dHMOs2s88CBA/1wyQCAs9GzAJA/uhYA8kXPAkC+6FnUg7IOI8ysQX0HES+GEN6QpBDC/hDCLyGEXyX9t6Tfe2tDCM+GEK4NIVyb9XO/AQAXjp4FgPzRtQCQL3oWAPJFz6IenHdmhPVN9HhOUk8I4Zmz8rbSPAlJWiTpk3wusZgYhAIA+aJnAaD/0KkAMDDoXwDIFz1bX857GCFpvqQVkrabWXcpe1rSUjPrkBQk7Zb0SC5XCAAAAAAAAAAACu28hxEhhPckeUdI/9P/lwMAAAAAAAAAAFJT9gBrAAAAAAAAAACAC8FhBAAAAAAAAAAAyBWHEQAAAAAAAAAAIFccRgAAAAAAAAAAgFxxGAEAAAAAAAAAAHLFYQQAAAAAAAAAAMgVhxEAAAAAAAAAACBXHEYAAAAAAAAAAIBcWQihdg9mdkDSntJvWyQdrNmD10Zq91Tv93NJCGHiQF8EUE/o2UKq93uia4FznNW19f78vRDcU+3Rs8A52NMWUj3fEz0LnIOeLaR6v6eyuramhxG/eWCzzhDCtQPy4DlJ7Z5Sux9gsEnxOcw9AagnKT5/uScA9SbF5zD3BKCepPj85Z7qFz+mCQAAAAAAAAAA5IrDCAAAAAAAAAAAkKuBPIx4dgAfOy+p3VNq9wMMNik+h7knAPUkxecv9wSg3qT4HOaeANSTFJ+/3FOdGrCZEQAAAAAAAAAAYHDgxzQBAAAAAAAAAIBc1fwwwswWmtnnZvaVmT1V68fvD2b2vJl9Z2afnJU1m9kaM/uy9Ov4gbzGSpnZZDNbb2Y7zOxTM1tVygt9X8BglELPSul1LT0LpCWFrk2tZyW6FkgJPVuf6FkgHSn0rJRe16beszU9jDCzIZL+U9LfS5otaamZza7lNfSTP0taeE72lKR1IYRpktaVfl8kZyQ9GUKYLel6SY+W/tkU/b6AQSWhnpXS61p6FkhEQl37Z6XVsxJdCySBnq1r9CyQgIR6Vkqva5Pu2Vq/M+L3kr4KIfxvCOG0pJcl3Vnja6haCGGTpMPnxHdKeqH08QuS7qrpRVUphNAbQthS+viYpB5J7Sr4fQGDUBI9K6XXtfQskJQkuja1npXoWiAh9GydomeBZCTRs1J6XZt6z9b6MKJd0jdn/X5vKUtBawiht/TxPkmtA3kx1TCzqZLmSvpQCd0XMEik3LNSIp1EzwKFl3LXJtNJdC1QaPRsAdCzQKGl3LNSIp2UYs8ywDoHIYQgKQz0dVwIMxstabWkJ0IIR8/+syLfF4D0FLWT6FkARVHkTqJrARRBkfuIngVQFEXtpFR7ttaHEd9KmnzW7/+mlKVgv5m1SVLp1+8G+HoqZmYN6vuX/MUQwhuluPD3BQwyKfesVPBOomeBZKTctYXvJLoWSAI9W8foWSAJKfesVPBOSrlna30YsVnSNDO71MyGSVoi6a0aX0Ne3pK0svTxSkl/GcBrqZiZmaTnJPWEEJ45648KfV/AIJRyz0oF7iR6FkhKyl1b6E6ia4Fk0LN1ip4FkpFyz0oF7qTUe9b63tVRwwc0+4Ok/5A0RNLzIYR/qekF9AMze0nS30lqkbRf0j9JelPSq5KmSNoj6d4QwrnDU+qWmf2tpHclbZf0ayl+Wn0/k6yw9wUMRin0rJRe19KzQFpS6NrUelaia4GU0LP1iZ4F0pFCz0rpdW3qPVvzwwgAAAAAAAAAADC4MMAaAAAAAAAAAADkisMIAAAAAAAAAACQKw4jAAAAAAAAAABArjiMAAAAAAAAAAAAueIwAgAAAAAAAAAA5IrDCAAAAAAAAAAAkCsOIwAAAAAAAAAAQK44jAAAAAAAAAAAALn6P3nZPMY4DvwgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2160x432 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = 10\n",
    "\n",
    "params = vae_module.get_params()[0]\n",
    "# We group the outputs of generate_reconstructions to be able to process them as a single symbol\n",
    "reconstructions = mx.sym.Group(vae.generate_reconstructions(mx.sym.Variable(\"random_digit\"), num_samples))\n",
    "# construct an executor by binding the parameters to the learned values\n",
    "params[\"random_digit\"] = mx.nd.array(random_picture.reshape((1,height*width)))\n",
    "reconstruction_exec = reconstructions.bind(ctx=ctx, args=params)\n",
    "\n",
    "# run the computation\n",
    "digits, latent_values = reconstruction_exec.forward()\n",
    "\n",
    "# transform output into numpy arrays\n",
    "digits = digits.asnumpy()\n",
    "latent_values = latent_values.asnumpy()\n",
    "\n",
    "# plot the reconstructed digits\n",
    "rows = int(num_samples / 5)\n",
    "plot, axes = plt.subplots(rows, 5,  sharex='col', sharey='row', figsize=(30,6))\n",
    "sample=0\n",
    "for row in range(rows):\n",
    "    for col in range(5):\n",
    "        axes[row][col].imshow(np.reshape(digits[sample,:],(width,height)), cmap=cm.Greys)\n",
    "        sample += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congrats!\n",
    "\n",
    "You have completed your first VAE tutorial. From here on you can modify this code to play with your own VAE ideas. Want to you use different data? Or vary the neural net structure for the generator or inference networks? Or use a different likelihood model? The world of probablistic modeling is yours to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
